---
title: "Homework 3: Binary and Count Regressions"
author: "Solution Set"
output: pdf_document
header-includes: 
 - \usepackage{amsthm}
 - \usepackage{amsmath}
 - \usepackage{amsfonts}
 - \usepackage{amscd}
 - \usepackage{amssymb}
 - \usepackage[sectionbib]{natbib}
 - \usepackage{url}
 - \usepackage{graphicx}
 - \usepackage{tikz-cd}
 - \usepackage{pgfplots}
 - \usepackage{geometry}
 - \usepackage{bm}
 - \usepackage{array,epsfig,fancyheadings,rotating}
 - \usepackage{multirow}
 - \usepackage{placeins}
---

\allowdisplaybreaks

\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\yobs}{y_{\text{obs}}}
\newcommand{\simiid}{\stackrel{iid}{\sim}}
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This homework set will cover problems concerning binary and count regression models. Point totals for specific problems are given, 10 points will be reserved for correct submission of the homework assignment.

\vspace*{1cm}


\noindent{\bf Problem 1} [10 points]: Manually write your own Fisher scoring algorithm which maximizes the logistic regression log likelihood for the CCSO example in the notes. Report $\hat\beta$ and reproduce the summary table (up to convergence tolerance differences) without using the \texttt{glm} or \texttt{summary} commands. You can ignore deviance residuals.

\vspace*{1cm}


### Solution 1:  

The log-likelihood is 

$$l(\beta) = \sum_{i = 1}^n y_ix_i^T\beta - \log(1+ exp(x_i^T\beta))$$
$$l'(\beta) = \sum_{i = 1}^n \left(y_ix_i - \frac{x_i}{1+exp(x_i^T\beta)}exp(x_i^T\beta)\right)$$

$$\implies l'(\beta) = X^T(Y - \pi)$$ where $\pi_i = \frac{exp(x_i^T\beta)}{1+exp(x_i^T\beta)}$

$$l''(\beta) = -\sum_{i = 1}^n \left( \frac{x_i^2}{(1+exp(x_i^T\beta))^2}exp(x_i^T\beta)\right)$$
 $$\implies l''(\beta) = -X^TWX$$ where $W = diag(\pi_i(1-\pi_i))$ 


Thus the Fisher scoring algorithm:

$$\beta^{(t+1)} = \beta^{(t)} + (X^TW^{(t)}X)^{-1}X^T(Y - \pi)$$

```{r,results='hide'}
# Reading in the data
library(data.table)
library(tidyverse)
library(MASS)
```

```{r,cache = TRUE}
CCSO = fread("https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv")
```

```{r P1}
# Pre-Processing the data 
CCSO_small <- CCSO %>% rename(Days = "Days in Jail", Age = "Age at Arrest",
Date = "BOOKING DATE", Sex = "SEX", Race = "RACE",
Crime = "CRIME CODE") %>%
mutate(atleastone = ifelse(Days > 0,1,0)) %>%
filter(Crime == "OTHER TRAFFIC OFFENSES") %>%
filter(Race %in% c("Asian/Pacific Islander","Black","White","Hispanic")) %>%
filter(Sex %in% c("Female","Male")) %>%
dplyr::select(atleastone, Age, Sex, Date, Race) %>%
mutate(Race = fct_drop(Race), Sex = fct_drop(Sex))
CCSO_small <- CCSO_small[complete.cases(CCSO_small), ]
head(CCSO_small)
```

```{r}
#Creating the model matrix
X = model.matrix(atleastone ~ -1 + Race + Sex + Age,data = CCSO_small)
n = nrow(X)
p = ncol(X)
Y = CCSO_small$atleastone

# Initializing the beta
beta = matrix(rep(0,6))

#Running the Fisher scoring iterations
for(t in 1:10)
{
  pi =  exp(X%*%beta)/(1+exp(X%*%beta))
  W = diag(c(pi*(1-pi)))
  beta = beta + solve(t(X) %*% W %*% X)%*%t(X)%*%(Y - pi)
}
```

```{r}
# The final values 
pi_CCSO =  exp(X%*%beta)/(1+exp(X%*%beta))
W_CCSO = diag(c(pi_CCSO*(1-pi_CCSO)))
var_matrix_CCSO = solve(t(X) %*% W_CCSO %*% X)
sd_beta = sqrt(diag(var_matrix_CCSO))
z_Val = beta/sd_beta
pvalue = 2*(1 - pnorm(abs(z_Val)))
```


```{r}
#Deviance results
deviance_res = -2*(t(Y)%*%X%*%beta - sum(log(1+exp(X%*%beta))))
beta_0 = 0
deviance_null =  -2*(beta_0*sum(Y) - n*log(1+exp(beta_0)))
AIC = deviance_res + 2*p
```

The summary table:
```{r}
tab = data.frame("Estimate" = beta,"Std.Error" = sd_beta,"z value" = z_Val, "Pvalue" = pvalue)
list("Coefficients" = tab, "Null deviation" = deviance_null, "Residual Deviance" = deviance_res, "Null df" = n, "Residual df" = n-p, "AIC" = AIC)
```

\vspace*{1cm}


\noindent{\bf Problem 2} [10 points]: Manually write your own Fisher scoring algorithm which maximizes the Poisson regression log likelihood for the Galapagos example in the notes. Report $\hat\beta$ and reproduce the summary table (up to convergence tolerance differences) without using the \texttt{glm} or \texttt{summary} commands. You can ignore deviance residuals.

\vspace*{1cm}

### Solution 2: 
The log-likelihood is 

$$l(\beta) = \sum_{i = 1}^n \left(y_ix_i^T\beta - exp(x_i^T\beta)\right)$$
$$l'(\beta) = \sum_{i = 1}^n \left(y_ix_i - x_iexp(x_i^T\beta)\right)$$

$$\implies l'(\beta) = X^T(Y - \pi)$$ where $\pi_i = exp(x_i^T\beta)$

$$l''(\beta) = -\sum_{i = 1}^n  x_i^2exp(x_i^T\beta)$$
 $$\implies l''(\beta) = -X^TWX$$ where $W = diag(\pi_i)$ 


Thus the Fisher scoring algorithm:

$$\beta^{(t+1)} = \beta^{(t)} + (X^TW^{(t)}X)^{-1}X^T(Y - \pi)$$

```{r}
library(faraway)
```

```{r P2}
#Pre-processing the data
data(gala)
gala <- gala %>%
mutate(Size = as.factor(1 + ifelse(Area > 1,1,0) + ifelse(Area > 25,1,0)))
head(gala)
```

```{r}
# Creating the model matrix
X = model.matrix(Species ~ Elevation + Nearest + Scruz + Adjacent + Size,data = gala)
n = nrow(X)
p = ncol(X)
Y = gala$Species

# Initialising the beta
beta = c(0,apply(X,2,mean)[-1]/apply(X,2,var)[-1])

#Running the fisher scoring iterations
for(t in 1:10)
{
  pi =  exp(X%*%beta)
  W = diag(c(pi))
  beta = beta + solve(t(X) %*% W %*% X)%*%t(X)%*%(Y - pi)
}
```

```{r}
# The final values
pi =  exp(X%*%beta)
W = diag(c(pi))

var_matrix = solve(t(X) %*% W %*% X)
sd_beta = sqrt(diag(var_matrix))
z_Val = beta/sd_beta
pvalue = 2*(1 - pnorm(abs(z_Val)))
```


```{r}
#Deviance results

deviance_res = -2*(t(Y)%*%X%*%beta - sum(pi)+ sum(Y - Y*log(Y)))
beta_0 = log(mean(Y))
deviance_null =  -2*(beta_0*sum(Y) - n*exp(beta_0) + sum(Y - Y*log(Y)))
AIC = -2*sum(dpois(Y,pi,log = TRUE)) + 2*(p)
```

The summary table:
```{r}
tab = data.frame("Estimate" = beta,"Std.Error" = sd_beta,"z value" = z_Val, "Pvalue" = pvalue)
list("Coefficients" = tab, "Null deviation" = deviance_null, "Residual Deviance" = deviance_res, "Null df" = n-1, "Residual df" = n-p, "AIC" = AIC)
```
\vspace*{1cm}


\noindent{\bf Problem 3} [5 points]: Derive the log-odds ratio of $x+ 1$ to $x$ when $Y= 1$, and observe that the log-odds ratio does not depend on $x$. Comment on this finding.

### Solution 3:

We know that in the logistic regression model we have 

$$logit(\pi(x)) = x\beta\quad \text{where } \pi(x) = E(Y|X= x) = P(Y = 1|X=x)$$

Thus the log of their ratio
\begin{align*}
\log\left(\frac{odds(Y = 1|X = x+1)}{odds(Y =1|X = x)}\right) 
&= log\left(\frac{ P(Y = 1|X=x+1)/ P(Y = 0|X=x+1)  }{ P(Y = 1|X=x+1)/ P(Y = 0|X=x+1) )}\right) \\
&=log\left(\frac{\pi(x+1)/(1 - \pi(x+1))}{\pi(x)/(1 - \pi(x))}\right)\\
&= log\left(\pi(x+1)/(1 - \pi(x+1))\right) - log\left(\pi(x)/(1 - \pi(x))\right)\\
&= logit(\pi(x+1)) - logit(\pi(x))\\
&= (x+1)\beta - x\beta\\
&= \beta
\end{align*}

Thus it does not depend on $X$. This shows that a unit increase in $X$ leads to an increase of beta in the log-odds ratio i.e a unit increase in x leads to the ratio of their odds increasing by $e^\beta$ 
\vspace*{1cm}

\noindent{\bf Problem 4} [10 points]: Complete the following parts:
\begin{itemize}
\item[(a)] Explain important findings and model information from the summary table produced by a call to summary(m1) in the CCSO example in the logistic regression notes. Keep in mind that we restricted attention to "other traffic offenses" in the CCSO example, and that this data is observational.
\item[(b)] Explain important findings and model information from the summary table produced by a call to summary(m1) in the Galapagos islands example in the count regression notes.
\end{itemize}

\vspace*{1cm}


### Solution 4:

```{r P4}
# Creating the logistic regression model for the CCSO model
m1 <- glm(atleastone ~ -1 + Race + Sex + Age, data = CCSO_small,
family = "binomial", x = "TRUE")
summary(m1)
```

The estimate column gives the estimate for $\beta$ for the logistic model $$logit(E(Y|X)) = X\beta$$ A unit increase in the predictor variable
$X_j$ corresponds to an increase of $\beta_j$ (estimated by $\hat \beta_j$) in the log-odds ratio with everything else being held
fixed. A simpler interpretation is that $\hat\beta_j > 0$ can be interpreted as: An increase in $X_j$ implies that $P(Y = 1|X = x)$ increases.

Thus


- Race being Asian/Pacific Islander decreases the propensity of incarcerations lasting longer than one day for "other traffic offenses"

- Race being Black also decreases the propensity of incarcerations lasting longer than one day for "other traffic offenses"

- Race being Hispanic also decreases the propensity of incarcerations lasting longer than one day for "other traffic offenses"

- Race being White also decreases the propensity of incarcerations lasting longer than one day for "other traffic offenses"

This shows that race does not really increase the propensity of incarceration.

- Sex being Male increases the propensity of incarcerations lasting longer than one day for "other traffic offenses"
- Age increasing also increases the propensity of incarcerations lasting longer than one day for "other traffic offenses"

The standard error column gives the standard error of the estimate of the $\beta$ coefficients. The Z-value and P-value help in detecting the significance of the covariates. At a level of $\alpha = 0.05$ we can see that all the covariates are significant.

The null deviance and residual deviance give information about the goodness of fit of the null model (with no covariates) and the submodel we consider respectively. To check if the sub-model is better than the saturated model we can do a $\chi^2$ test because under $H_0$ (The submodel is a better fit)

$$ D(y ; \hat {\mu} )  \sim  \chi^2_{n-p},$$ where D is the deviance.

```{r}
pchisq(m1$deviance, df = m1$df.residual, lower = FALSE)
```

Since the p-value is 1 this shows that the submodel is indeed a good fit to the data. We can also check if the null model ($M_0$) is better than the submodel ($M_1$) we choose.

$$H_0 \;:\;M_0 \text{ true }\quad  H_a \;:\;M_1 \text{ true , but not } M_0$$
Then $$D(y; \hat \mu_0) - D(y; \hat \mu_1) \sim \chi^2_{p_0 - p_1}$$ where $D(y; \hat \mu_0)$ is the null deviance and $D(y; \hat \mu_1)$ is the residual deviance.

```{r}
pchisq(m1$null.deviance - m1$deviance, df = m1$df.null - m1$df.residual,
lower = FALSE)
```
Since the pvalue is 0 this means that the submodel we choose is a better fit than the null model.

(b) Summarize the summary tables produced by a call to summary(m1) in the Galapagos islands
example in the count regression notes.
```{r}
m2 <- glm(Species ~ Elevation + Nearest + Scruz + Adjacent + Size,
family = "poisson", data = gala, x = TRUE)
summary(m2)
```

The estimate column gives the estimate for $\beta$ for the logistic model $$log(E(Y|X)) = X\beta$$. A unit increase in the predictor variable
$X_j$ corresponds to an increase of $\beta_j$ (estimated by $\hat {\beta}_j$) in the log of the mean response with everything else being held
fixed. A simpler interpretation is that $\hat{\beta}_j > 0$ can be interpreted as: An increase in $X_j$ implies that the mean response increases.

Thus

- Elevation increases the number of plant species found on each island

- Nearest increases the number of plant species found on each island

- Scruz decreases the number of plant species found on each island

- Adjacent also decreases the number of plant species found on each island

- Size of the island being in category 2 and 3 also increases the number of plant species found on each island


The standard error column gives the standard error of the estimate of the $\beta$ coefficients. The Z-value and P-value help in detecting the significance of the covariates. At a level of $\alpha = 0.05$ we can see that all the covariates are significant.

The null deviance and residual deviance give information about the goodness of fit of the null model (w
ith no covariates) and the submodel we consider respectively. To check if the sub-model is better than the saturated model we can do a $\chi^2$ test because under $H_0$ (The submodel is a better fit)
$$D(y; \hat {\mu} )  \sim \chi^2_{n-p},$$ where D is the deviance.

```{r}
pchisq(m2$deviance, df = m2$df.residual, lower = FALSE)
```

Since the p-value is very small this shows that the submodel not really a good fit to the data. We prefer the saturated model over it. We can also check if the null model ($M_0$) is better than the submodel ($M_1$) we choose.

$$H_0 \;:\;M_0 \text{ true }\quad  H_a \;:\;M_1 \text{ true , but not } M_0$$
Then $$D(y; \hat \mu_0) - D(y; \hat \mu_1) \sim \chi^2_{p_0 - p_1}$$ where $D(y; \hat \mu_0)$ is the null deviance and $D(y; \hat \mu_1)$ is the residual deviance.

```{r}
pchisq(m2$null.deviance - m2$deviance, df = m2$df.null - m2$df.residual,
lower = FALSE)
```

Since the pvalue is 0 this means that the submodel we choose is a better fit than the null model.

\vspace*{1cm}

###

\noindent{\bf Problem 5} [10 points]: Derive expressions and compute standard errors se($\hat\mu$) in the logistic regression CCSO example without using \texttt{predict.glm}. Then construct Wald based confidence intervals for the estimated mean value parameters. Also construct confidence intervals $( g(\hat\beta - z_{\alpha/2}\text{s}e(\hat{\beta})), g(\hat\beta + z_{\alpha/2}\text{s}e(\hat{\beta})) )$. Comment on the differences between these two confidence intervals for $\hat{\mu}$.
 
\vspace*{1cm}

###solution 5

We know that $$\sqrt n(\hat \beta - \beta) \xrightarrow{d} N(0,\Sigma^{-1})$$ 

where $\Sigma = X^T W X$, $W = diag(\mu_i(1-\mu_i))$ and $\mu = e^{X\beta}/(1+  e^{X\beta})$

Now $\mu_i = g(\beta) = e^{M_i^T\beta}/(1+  e^{M_i^T\beta})$ $\implies g'(\beta) = M_i*\mu_i(1-\mu_i)$

Thus by the delta method
$$\sqrt n(\hat \mu_i - \mu_i) \xrightarrow{d} N(0,\hat\mu_i^2(1-\hat \mu_i)^2M_i^T\Sigma^{-1}M_i)$$

Thus our estimation of the SE is:

```{r P5}
#Creating the model matrix
X = model.matrix(atleastone ~ -1 + Race + Sex + Age,data = CCSO_small)
#Calculating the se
se_pihat = sqrt(apply(X,1,function(j) t(j)%*%var_matrix_CCSO%*%j))*pi_CCSO*(1-pi_CCSO)
se_pihat[1:20]
```

The Wald based confidence intervals for the estimated mean value parameters are $$\hat \mu_i(x) \pm z_{1-\alpha/2}\sigma_i \quad \text{ where } \sigma_i = \hat\mu_i(1-\hat \mu_i)\sqrt{M_i^T\Sigma^{-1}M_i}$$

```{r}
#Creating the conf intervals
conf_lower = pi_CCSO - qnorm(0.975)*se_pihat
conf_upper = pi_CCSO + qnorm(0.975)*se_pihat
waldci = cbind(conf_upper, conf_lower)
waldci = waldci %>% as.data.frame()  %>%
  mutate(length = conf_upper -  conf_lower)
head(waldci)

```





And, for the other confidence interval type $g(\hat\beta + z_{\alpha/2}\text{s}e(\hat{\beta})) )$:

```{r}
m1 <- glm(atleastone ~ -1 + Race + Sex + Age, data = CCSO_small,
          family = "binomial", x = "TRUE")

betahat = m1$coefficients
M = m1$x
alpha = 0.025
z = qnorm(p = 1-alpha)
n = nrow(M)
pici_upper = 1/(1 + exp( - M %*% (betahat + z*diag(vcov(m1))) ))
pici_lower = 1/(1 + exp( - M %*% (betahat - z*diag(vcov(m1))) ))
pici = cbind(pici_upper, pici_lower)
pici = pici %>% as.data.frame()  %>%
  mutate(length = pici_upper -  pici_lower)
head(pici)
```

Then, the average length of the Wald and plug-in approaches are given as:
```{r CI comparison}
avg_length_wald = round(mean(waldci$length), digits=4)
avg_length_wald
avg_length_pi = round(mean(pici$length), digits=4)
avg_length_pi
```
Then, the average Wald CI is somewhat larger than the average plug-in CI.


\noindent{\bf Problem 6} [10 points]: Construct a nonparametric bootstrap procedure that estimates the uncertainty associated with both estimates of the average treatment effect (ATE) of online learning in the logistic regression notes. Do the conclusions change when we factor in the uncertainty obtained from the nonparametric bootstrap procedure? Explain.

\vspace*{1cm}

### Solution 6:

Here we are estimating the ATE for the scores earned by students in online learning as opposed to in-person learning.  

```{r,cache = T}

#Reading in the data

dat = read.csv("/Users/diptarka/Documents/GitHub/stat528resources/notes/3_binary_response/online.csv")
dat_small <- dat %>% dplyr::select(Online, ACTMath, ACTMajor, ACT, Gender,
International, F17, S18, S19, Fa19, FR, SO, JR)

ATE_alt = NULL

#Taking 1000 bootstrap samples
for(i in 1:1000)
{
  rand = sample(nrow(dat_small),replace = T)
  m <- glm(Online ~., data = dat_small[rand,], family = "binomial")
  trt <- dat_small[rand,]$Online
  preds <- predict(m, type = "response")
  weights_alt_trt <- 1 / sum(trt / preds) * trt /preds
  weights_alt_notrt <- 1 / sum((1 - trt)/(1 - preds)) * (1-trt)/(1-preds)
  dat_new <- data.frame(dat[rand,], weights = weights_alt_trt - weights_alt_notrt)
  ATE_alt <- c(ATE_alt,sum(weights_alt_trt * dat_new$ObjExam) -
sum(weights_alt_notrt * dat_new$ObjExam))
}

mean(ATE_alt)
var(ATE_alt)
quantile(ATE_alt,prob = c(0.025,0.975))

```
Since the mean and variance are small and the confidence intreval contains 0 we can still conclude that there is no difference between the two types of learning. 
```{r,cache = T}
ATE_DR = NULL
for(i in 1:1000)
{
  rand = sample(nrow(dat),replace = T)
  trt = dat_small[rand,]$Online
  m <- glm(Online ~., data = dat_small[rand,], family = "binomial")
  preds <- predict(m, type = "response")
  dat_boot = dat[rand,]
  m_trt <- lm(ObjExam ~ ACTMath + ACTMajor + ACT + International + Gender +
FR + SO + JR + F17 + S18 + S19,
data = dat_boot[trt == 1, ])
  Y_trt <- predict(m_trt, newdata = dat_boot)
  m_notrt <- lm(ObjExam ~ ACTMath + ACTMajor + ACT + International + Gender +
FR + SO + JR + F17 + S18 + S19,
data = dat_boot[trt == 0, ])
  Y_notrt <- predict(m_notrt, newdata = dat_boot)
  ATE_DR <- c(ATE_DR,mean( (dat_boot$ObjExam * trt - (trt - preds) * Y_trt) / preds -
(dat_boot$ObjExam * (1 - trt) + (trt - preds)*Y_notrt) / (1 - preds)))
}

mean(ATE_DR)
var(ATE_DR)
quantile(ATE_DR,prob = c(0.025,0.975))

```
Since the mean and variance are small even for the robust estimate and the confidence intreval contains 0 we can still conclude that there is no difference between the two types of learning.


\vspace*{1cm}

### Solution 7
\noindent{\bf Problem 7} [15 points]: Use the \texttt{dvisits} data in the \texttt{faraway} package to answer the follow parts:
\begin{itemize}

	\item[(a)] Make plots which show the relationship between the response variable,
doctorco, and the potential predictors, age and illness.

	\item[(b)] Combine the predictors chcond1 and chcond2 into a single three-level factor. Make an appropriate plot showing the relationship between this factor and the response. Comment.
	\item[(c)] Build a Poisson regression model with doctorco as the response and sex, age, agesq, income, levyplus, freepoor, freerepa, illness, actdays, hscore and the three-level condition factor as possible predictor variables. Considering the deviance of this model, does this model fit the data?
	\item[(d)] Plot the residuals and the fitted values — why are there lines of observations on the plot? Make a QQ plot of the residuals and comment.
	\item[(e)] Use a stepwise AIC-based model selection method. What sort of person would be predicted to visit the doctor the most under your selected model?
	\item[(f)] For the last person in the dataset, compute the predicted probability distribution for their visits to the doctor, i.e., give the probability they visit 0, 1, 2, etc. times.
	\item[(g)] Tabulate the frequencies of the number of doctor visits. Compute the expected frequencies of doctor visits under your most recent model. Compare the observed with the expected frequencies and comment on whether it is worth fitting a zero-inflated count model.
	\item[(h)]	Fit a comparable (Gaussian) linear model and graphically compare the fits. Describe how they differ.

\end{itemize}




### Solution 7:

(a) Make plots which show the relationship between the response variable, doctorco, and the
potential predictors, age and illness.


```{r P7}
data(dvisits)
plot(dvisits$age,dvisits$doctorco)
```

```{r}
plot(dvisits$illness,dvisits$doctorco)
```




(b) Combine the predictors chcond1 and chcond2 into a single three-level factor. Make an appropriate
plot showing the relationship between this factor and the response. Comment.

We create a new variable `chcond` which takes 3 factor values 
 
 - 1 if the patient has a chronic condition(s) but is not limited in activity
 - 2 if the patient has a chronic condition(s) but is limited in activity
 - 0 Otherwise

```{r}
chcond = as.factor(dvisits$chcond1+2*dvisits$chcond2)
plot(chcond,dvisits$doctorco)
```


From the plot we can see that patients which chronic conditions which limit activity have more visits to the doctor. This possible is a factor which influences the response variable. 


(c) Build a Poisson regression model with doctorco as the response and sex, age, agesq, income,
levyplus, freepoor, freerepa, illness, actdays, hscore and the three-level condition factor as
possible predictor variables. Considering the deviance of this model, does this model fit the
data?

```{r}
dat = dvisits %>% dplyr::select(doctorco, sex, age, agesq, income,
levyplus, freepoor,freerepa, illness, actdays, hscore)
dat = cbind(dat,"chcond" = chcond)
head(dat)
```

```{r}
#Creating the model 
mod = glm(doctorco~.,data = dat,family = "poisson",x  =TRUE)
summary(mod)
```
```{r}
#Testing for the goodness of fit of the model against the saturated moddel
pchisq(mod$deviance, df =  mod$df.residual, lower = FALSE)
```
Since the pvalue is 1 we can conclude that the model is indeed a better fit than the saturated model. 
```{r}
pchisq(mod$null.deviance - mod$deviance, df = mod$df.null - mod$df.residual,
lower = FALSE)  %>%  round(4)
```
Since the pvalue is nearly 0 we can conclude that the model is also better than the null model. Thus it is a appropriate fit to the data. 


(d) Plot the residuals and the fitted values — why are there lines of observations on the plot?
Make a QQ plot of the residuals and comment.

```{r}
res = residuals(mod)
fit = fitted(mod)

plot(res,fit)
```

We observe lines of observations because most of the variables are factor variables with a small number of levels. 
```{r}
qqnorm(res)
abline(0, 1)
```

The QQ-plot shows that the residuals do not follow a normal distribution very well indicating the normality of residuals assumption is not reasonable. 

(e) Use a stepwise AIC-based model selection method. What sort of person would be predicted
to visit the doctor the most under your selected model?

```{r}

#Selecting the model
library(MASS)
mod_Select = stepAIC(mod)

#Outputting the best models
mod_Select$anova
```
```{r}
# The beta coefficients of our best moddel
beta = mod_Select$coefficients
beta
```
We can see that the number of doctor consultations increases when the patient is female, with increasing age, with low income, if covered by private health insurance, not covered by the government insurance for low income, high number of illness,  high number of days of reduced activity, bad health score and with presence of chronic conditions. This indicates a poorer older woman with private insurance and higher number of illness is predicted to visit doctor more often.


(f) For the last person in the dataset, compute the predicted probability distribution for their
visits to the doctor, i.e., give the probability they visit 0, 1, 2, etc. times.

```{r}
options (scipen = 99)
X = mod_Select$x
Y = mod_Select$y
hat_lambda_last = exp(t(X[nrow(dat),])%*%beta)
data.frame("Value" = 0:9, "Prob" = dpois(0:9,hat_lambda_last) %>%  round(6) )
```




(g) Tabulate the frequencies of the number of doctor visits. Compute the expected frequencies
of doctor visits under your most recent model. Compare the observed with the expected
frequencies and comment on whether it is worth fitting a zero-inflated count model.

```{r}
observed_freq <- with(dvisits, table(doctorco))
est <- matrix(nrow=dim(dvisits)[1], ncol=10)
for(i in 1:dim(dvisits)[1]){
est[i,] <- dpois(0:9, fitted.values(mod_Select)[i])
}
expected_freq <- colMeans(est)*dim(dvisits)[1]
cbind.data.frame(observed_freq, expected_freq)
```

From the two tables, the observed and expected frequencies are close enough and thus it does not seem worth fitting a zero inflated model.

(h) Fit a comparable (Gaussian) linear model and graphically compare the fits. Describe how
they differ.

```{r}
dvisitsmod_lm <- lm(Y ~  X)
summary(dvisitsmod_lm)

par(mfrow=c(1,2))
plot(mod_Select, which=1)
title(main = "Poisson regression\n")
plot(dvisitsmod_lm, which=1)
title(main = "linear regression\n")

par(mfrow=c(1,2))
plot(mod_Select, which=2)
title(main = "Poisson regression\n")
plot(dvisitsmod_lm, which=2)
title(main = "linear regression\n")
```


This seems to indicate how the Poisson regression is a little better because the line for the residuals plot is much more linear around zero, along with the Q-Q plot. In conclusion, we can see that even though we need to account for overdispersion in the Poisson model it is still a better fit than the linear model. 


\vspace*{1cm}

\noindent{\bf Problem 8} [20 points]: Analyze the CCSO data set with Days in Jail as the response variable. You are allowed to dichotomize the response into a binary variable. Restrict attention to other traffic offenses as done in class. Your analysis needs to consider the variables considered in class as well as repeat offenders, multiple offenses, released reason, and agency. The determination of repeat offenders and multiple offenses can be done via the jacket number variable. Report interesting significant and null findings and determine that your final model is appropriate. You are allowed to use other inferential techniques than GLM. If you do so, then you need to justify your choices.

\vspace*{1cm}

### Solution 8


#### Data Wrangling: 

We first select the necessary data, here we focus on `OTHER TRAFFIC OFFENSES` type crimes. Our response variable is the binary variable denoting whether the offender stayed in jail for at least one day or not. We also restrict ourselves with some specific Race, Sex, and Arrest Agencies. 

```{r P8}
CCSO <- fread("https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv")
```

The full data has `r nrow(CCSO)` observations and  `r ncol(CCSO)`  features. 


```{r}
## data wrangling
CCSO_imp <- CCSO %>% rename(Days = "Days in Jail", Age = "Age at Arrest",
                              Date = "BOOKING DATE", Sex = "SEX", Race = "RACE",
                              Crime = "CRIME CODE", Agency = "ARREST AGENCY", JNum = "JACKET NUMBER") %>%
  mutate(atleastone = ifelse(Days > 0,1,0)) %>%
  filter(Crime == "OTHER TRAFFIC OFFENSES") %>%
  filter(Race %in% c("Asian/Pacific Islander","Black","White","Hispanic")) %>%
  filter(Sex %in% c("Female","Male")) %>%
  ## Agency (and possible interactions with Agency) is interesting if you want to go deepe filter(Agency %in% c("Champaign County Sherriff's Office", "Champaign Police Department"
  filter(Agency %in%   c( "Illinois State Police", "Rantoul Police Department",
         "University of Illinois Police Department", "Urbana Police Department",
         "Champaign County Sherriff's Office","Champaign Police Department") ) %>% 
  dplyr::select(atleastone, Age, Sex, Date, Race, Agency, JNum, `RELEASED REASON`, `EMPLOYMENT STATUS`, `INCARCERATION REASON`) %>%
  mutate(Race = fct_drop(Race), Sex = fct_drop(Sex), Agency = fct_drop(Agency))

CCSO_imp <- CCSO_imp[complete.cases(CCSO_imp), ]

```


Now, we will combine categories for the features `RELEASED REASON`, `EMPLOYMENT STATUS`, `INCARCERATION REASON` in order to reduce number of factors in these features. 



```{r}

CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Cash Bond Posted","Paid Fine, Court Costs or Restitution            Y")] = "CashBonds"
CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Credit Card Bond Posted")] = "CardBonds"
CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Placed on Probation                              Y","Conditional Discharge                            Y","Court Supervision                                Y")] = "Conditional Release"

CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Release on Personal Recognizance                 Y","CCSO Release on Recognizance","Ordered Released                                 Y","Released at court","RELEASED TO DEPT. CHILDREN AND FAMILY SERVICES","Book N Release                                   Y")] = "Released"
CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Served Sentence of Incarceration                 Y","Acquitted or Found Not Guilty                    Y")] = "Served/Acquitted"
CCSO_imp$`RELEASED REASON`[CCSO_imp$`RELEASED REASON` %in% c("Transfer to other county/state authorities       Y","Transfer to Military or Federal Authority        Y","Transfer to Mental Health Treatment Facility     Y","Transfer to substance abuse treatment facility   Y","17yoa transfer to CCCC                           Y","Sentenced (transfer) to State Corrections        Y")] = "Transfered"
CCSO_imp$`RELEASED REASON`[!(CCSO_imp$`RELEASED REASON` %in% c("Bonds paid","Conditional Release","Released","Served/Acquitted","Transfered"))] = "Other"

CCSO_imp$`EMPLOYMENT STATUS`[CCSO_imp$`EMPLOYMENT STATUS` %in% c("Employed - Full Time","Employed - Part Time","Self Employed")] = "Employed"
CCSO_imp$`EMPLOYMENT STATUS`[CCSO_imp$`EMPLOYMENT STATUS` %in%  c("Student","Retired")] = "Student/Retired"
CCSO_imp$`EMPLOYMENT STATUS`[CCSO_imp$`EMPLOYMENT STATUS` %in% c("Unemployed","Laid Off")] ="Unemployed"   


CCSO_imp$`INCARCERATION REASON`[CCSO_imp$`INCARCERATION REASON` %in% c("Arrest - Without Warrant","Arrest - Other County Warrant","Arrest - Champaign County Warrant","Arrest - City Warrant","Arrest - DOC Warrant","Arrest - Other State Warrant")] = "Arrest"
CCSO_imp$`INCARCERATION REASON`[CCSO_imp$`INCARCERATION REASON` %in% c("FTA - CITY WARRANT (OV)","FTA - OTHER COUNTY WARRANT","FTA - Civil Warrant","FTA - Traffic Warrant","FTA - Criminal Warrant")] = "FTA"
CCSO_imp$`INCARCERATION REASON`[CCSO_imp$`INCARCERATION REASON` %in% c("Sentenced - EHD","Sentenced")] = "Sentenced"
CCSO_imp$`INCARCERATION REASON`[!(CCSO_imp$`INCARCERATION REASON` %in% c("Arrest","FTA","Sentenced"))] = "Other"

CCSO_small <- CCSO_imp %>% rename(Inc_Reason = "INCARCERATION REASON",
                            Emp_Status = "EMPLOYMENT STATUS", 
                            Rls_Reason = "RELEASED REASON")


```


Next, we add two derived features as directed in the problem: One denoting whethere the offender did multiple offenses in the same day (called `multiple`), and the other denoting whether they are repeat offenders (called `repeatOffender`) 

```{r}

date_and_jnum <- paste(CCSO_small$Date, CCSO_small$JNum)
dup_date_and_jnum <- date_and_jnum[duplicated(date_and_jnum)]
dup_date_and_jnum <- unique(dup_date_and_jnum)
CCSO_small <- cbind(CCSO_small, as.numeric(is.element(date_and_jnum, dup_date_and_jnum)))
CCSO_small <- CCSO_small %>% rename(multiple = 'V2')


CCSO_small <- cbind(CCSO_small, as.numeric(duplicated(CCSO_small$JNum)))
CCSO_small <- CCSO_small %>% rename(repeatOffender = 'V2')

CCSO_small <- CCSO_small %>% dplyr::select(-c('JNum', 'Date'))

```


We show three rows from our final dataset. It has `r nrow(CCSO_small)` observations and  `r ncol(CCSO_small)` features

```{r}
head(CCSO_small, 3)
```

### Model Fitting 

Let us fit our full model here 

```{r}

mymod <- glm(atleastone ~ -1 + ., data = CCSO_small,
             family = "binomial", x = "TRUE")

summary(mymod)

```



Let us first test the goodness of the model against the null model. We can see the model is a better fit than the null model

```{r}

#Testing against the null model
pchisq(mymod$null.deviance - mymod$deviance, df = mymod$df.null - mymod$df.residual,
lower = FALSE)
```



#### Model Selection

We can see not all the features considered show a significant effect on the response. Thus, we can do feature selection via stepwise method

```{r}

mod_Select = stepAIC(mymod)

summary(mod_Select)

```

The `Age` feature gets completely removed. Let us examine if this is a good fit. We can notice this model is significantly better than the null model and the full model is not significantly better than this model. We are satisfied with this selected model

```{r}
#Testing against the saturated model
pchisq(mod_Select$deviance - mymod$deviance, df = mod_Select$df.residual - mymod$df.residual, lower = FALSE)

#Testing against the null model
pchisq(mymod$null.deviance - mod_Select$deviance, df = mymod$df.null - mod_Select$df.residual,
lower = FALSE)

```


#### Discussion
 
Now, finally - if we look at the summary table - the features that seem most useful for predicting the response are Some interesting findings are: 


 - * Race again has significant effect on response; Especially being black seems to be associated with longer incarceration

- * One agency ‘Rantoul Police Department’ stands out among all agencies. It appears people arrested by this agency tends to have longer incarcerations. 

- * Among incarceration reason, ‘FTA’ reasons tend to make incarceration longer. This maybe because since they already have failed to appear. 

- * Multiple offenses is related to longer incarcerations, per expectations. However, repeat offenses do not seem to have such strong associations.  s

- * Being Male also seems to be more problematic than being female. 



We can thus understand, black male are more likely to spend at least one day in jail than others. Specially if they are under Rantoul PD and/or have FTA against them. However, we should remember this is an observational data and we shouldn't make causal connections with any confidence. 

