\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage{url}
\usepackage{graphicx,times}
\usepackage{tikz-cd}
\usepackage{array,epsfig,fancyheadings,rotating}
\usepackage{geometry}
\usepackage[usenames]{color}

\geometry{margin=1in}
\renewcommand{\baselinestretch}{1.2}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Proj}{\textbf{P}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\rootn}{\sqrt{n}}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\indep}{\perp\!\!\!\perp}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\set}[1]{\{\, #1 \,\}}

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\etr}{etr}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\vecop}{vec}
\DeclareMathOperator{\vech}{vech}


\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{prop}{Proposition}


\pagestyle{fancy}
\def\n{\noindent}
\lhead[\fancyplain{} \leftmark]{}
\chead[]{}
\rhead[]{\fancyplain{}\rightmark}
\cfoot{}
%\headrulewidth=0pt


\setcounter{page}{1}
\setcounter{equation}{0}

\newcommand\red[1]{{\color{red}#1}}

\allowdisplaybreaks

\title{Exponential Family Notes}
\author{Daniel J. Eck}
\date{}



\begin{document}

\maketitle


\section*{Exponential families}

An \emph{exponential family of distributions} is a parametric statistical model having log likelihood that takes the form 
\begin{equation} \label{expolog}
	l(\theta) = \inner{y, \theta} - c(\theta),
\end{equation}
where $y$ is a vector statistic and $\theta$ is a vector parameter, and 
\begin{enumerate}
	\item[] $\inner{y,\theta}$ is the usual inner product,
	\item[] $c(\theta)$ is the cumulant function.
\end{enumerate}
This uses the convention that terms that do not contain the parameter vector can be dropped from a log likelihood; otherwise additional terms also appear in \eqref{expolog}. When the log likelihood can be expressed as \eqref{expolog} we say that $y$ is the {\bf canonical statistic} and $\theta$ is the {\bf canonical parameter}.

\vspace{0.5cm}\noindent {\bf Example (Binomial distribution)}: The Binomial distribution Bin($n$, $p$) can be parameterized as an exponential distribution parameterized as \eqref{expolog}. We can write
\begin{align*}
    l(p) &= \log\left({n \choose y}\right) + y\log(p) +(n-y)\log(1-p) \\
  	  &\propto y\log\left(\frac{p}{1-p}\right) + n\log(1 - p) \\
  	  &= y\theta - n\log\left(1 + e^\theta\right) \\
  	  &= \inner{y,\theta} - c(\theta),
\end{align*}
where 
\begin{enumerate}
	\item[] $\theta = \log\left(\frac{p}{1-p}\right)$ and $p = \frac{e^\theta}{1 + e^\theta}$
	\item[] $c(\theta) = n\log\left(1 + e^\theta\right)$
	\item[] $\log\left({n \choose y}\right)$ is a function of the statistic $y$ that is dropped because it does not contain the parameter. \qed
\end{enumerate}




\section*{Densities}

With our definitions we have some trouble writing down densities. First $y$ is not the data; rather it is a statistic, a function of the data. Let $w$ represent the full data, then the densities have the form
\begin{equation} \label{expodens}
  f_\theta(w) = h(w)\exp\left(\inner{Y(w),\theta} - c(\theta)\right)
\end{equation}
and the word ``density'' here can refer to a probability mass function (PMF) or a probability density function (PDF) or to a probability mass-density function (PMDF) if we are referring to a distribution that is partly discrete and partly continuous (either some components of the $Y$ are discrete and some continuous or some components are a mixture of discrete and continuous) or to a density with respect to an arbitrary positive measure in the sense of probability theory. The $h(w)$ arises from any term not containing the parameter that is dropped in going from log densities to log likelihood. We saw this in our Binomial distribution derivation. 

The function $h$ has to be nonnegative, and any point $w$ such that $h(w) = 0$ is not in the support of any distribution in the family.


\vspace{0.5cm}\noindent {\bf Example (Binomial distribution)}: The Binomial distribution Bin($n$, $p$) can be parameterized as an exponential distribution. We can write
\begin{align*}
  	f_p(y) &= {n \choose y}p^y(1-p)^{n-y} \\
  	  &= h(y)\exp\left(y\log(p) + (n-y)\log(p)\right) \\
  	  &= h(y)\exp\left(y\log\left(\frac{p}{1-p}\right) + n\log(p)\right) \\
  	  &= h(y)\exp\left(y\theta - n\log\left(1 + e^\theta\right)\right) \\  	  
  	  &= h(y)\exp\left(\inner{y,\theta} - c(\theta)\right) \\
  	  &= f_\theta(y)
\end{align*}
where 
\begin{enumerate}
	\item[] $\theta = \log\left(\frac{p}{1-p}\right)$ and $p = \frac{e^\theta}{1 + e^\theta}$
	\item[] $c(\theta) = n\log\left(1 + e^\theta\right)$
	\item[] $h(y) = {n \choose y}$ \qed
\end{enumerate}


\vspace{0.5cm}\noindent {\bf Example (Normal distribution)}: The Normal distribution $N(\mu, \sigma^2)$ can be parameterized as an exponential distribution. We can write
\begin{align*}
  	f_{\mu,\sigma^2}(w) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(w-\mu)^2}{2\sigma^2}\right) \\
  	  &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{w^2-2w\mu+\mu^2}{2\sigma^2}\right) \\
  	  &= \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{w^2}{2\sigma^2} + \frac{w\mu}{\sigma^2} - \frac{1}{2}\left(\frac{\mu^2}{\sigma^2} + \log(\sigma^2)\right)\right) \\
 	  &= h(w)\exp\left(\inner{Y(w),\theta} - c(\theta)\right) \\
  	  &= f_\theta(w)
\end{align*}
where 
\begin{enumerate}
	\item[] $h(w) = \frac{1}{\sqrt{2\pi}}$
	\item[] $Y(w) = (w,\; -w^2)^T$ and $\theta = \left(\frac{\mu}{\sigma^2},\; \frac{1}{2\sigma^2}\right)^T$
	\item[] $c(\theta) = \frac{1}{2}\left(\frac{\theta_1^2}{2\theta_2} - \log(2\theta_2)\right)$ \qed
\end{enumerate}


\section*{Ratios of densities}
When we look at a ratio of two exponential family densities with canonical parameter vectors $\theta$ and $\psi$, the $h(w)$ term cancels, and
\begin{equation} \label{Radon}
  f_{\theta;\psi}(w) = e^{\inner{Y(w),\theta - \psi} - c(\theta) + c(\psi)}	
\end{equation}
is a density of the distribution with canonical parameter $\theta$ taken with respect to the distribution with canonical parameter $\psi$ (a Radon-Nikodym derivate in probability theory). For any $w$ such that $h(w) = 0$ \eqref{Radon} still makes sense because such $w$ are not in the support of the distribution with parameter value $\psi$ and hence do not not contribute to any probability or expectation calculation, so it does not matter how \eqref{Radon} is defined for such $w$. Now, since \eqref{Radon} is everywhere strictly positive, we see that every distribution in the family has the same support.




\section*{Cumulant Functions}
Being a density, \eqref{expodens} must sum, integrate, or sum-integrate to one. Hence, 
\begin{align*}
	1 &= \int f_\theta(w) dw \\ 
	  &= \int h(w)\exp\left(\inner{Y(w),\theta} - c(\theta)\right) dw \\
	  &= \exp\left(-c(\theta)\right) \int \exp\left(\inner{Y(w),\theta}\right) h(w) dw.
\end{align*}
Rearranging the above implies that 
$$
  c(\theta) = \log\left(\int \exp\left(\inner{Y(w),\theta}\right) h(w) dw\right).
$$
Being the expectation of a strictly positive quantity, the expectation here must always be strictly positive, so the logarithm is well-defined. By convention, for $\theta$ such that the expectation does not exist, we say $c(\theta) = \infty$.

In probability theory the cumulant function is the log Laplace transformation corresponding to the \emph{generating measure} of the exponential family which is given by $\lambda(dw) = h(w)dw$ when the random variable is continuous. Under this formulation
$$
  c(\theta) = \log\left(\int \exp\left(\inner{Y(w),\theta}\right) \lambda(dw)\right).
$$
In our log likelihood based definition of the exponential family \eqref{expolog}, the dropped terms which do not appear in the log likelihood are incorporated into the counting measure (discrete distributions) or Lebesgue measure (continuous distributions).



\section*{Full families}
Define
\begin{equation} \label{parmspace}
  \Theta = \{ \theta : c(\theta) < \infty \}	.
\end{equation}
Then \eqref{expolog} and \eqref{expodens} define a distribution for all $\theta \in \Theta$, thus giving a statistical model that may be larger than the originally given model. We say an exponential family is \emph{full} if its canonical parameter space is \eqref{parmspace}. Many commonly used statistical models are full exponential families. There is literature about so-called ``curved exponential families'' and other non-full exponential families, but we will not discuss them.



\section*{Moment and cumulant generating functions}
We no longer fuss about $Y(w)$ and will suppress $w$ when writing $Y$. We still mention the function $h$ in \eqref{expodens} which is now derived with respect to $Y$ instead of $w$. This distinction is under the hood and not that important. The moment generating function of the canonical statistic, if it exists, is given by 
\begin{equation} \label{mgf}
\begin{split}
	M_\theta(t) &= \E_\theta\left(e^{\inner{Y, t}}\right) \\
	  &= \int e^{\inner{y, t}} h(y)e^{\left(\inner{y, \theta} - c(\theta)\right)} dy \\
	  &= \int h(y)e^{\left(\inner{y, t + \theta} - c(\theta)\right)}dy \\
	  &= \int h(y)e^{\left(\inner{y, t + \theta} - c(\theta) \pm c(\theta + t)\right)}dy \\
	  &= e^{c(\theta + t) - c(\theta)}.
\end{split}
\end{equation}
The moment generating function exists if it is finite on a neighborhood of zero, that is, if $\theta$ is an interior point of the full canonical parameter space \eqref{parmspace}. For other $\theta$ we say the moment generating function does not exist.

By the theory of moment generating functions, if the moment generating function exists, then moments of all orders exist and ordinary moments are given by the derivatives of $M_\theta(t)$ evaluated at zero. In particular,
\begin{align*}
  \E_\theta(Y) &= \nabla M_\theta(0) = \nabla c(\theta) \\	
  \E_\theta(YY^T) &= \nabla^2 M_\theta(0) = \nabla^2 c(\theta) + [\nabla c(\theta)][\nabla c(\theta)]^T.	  
\end{align*}
A log moment generating function is called a \emph{cumulant generating function} and its derivatives evaluated at zero are called the \emph{cumulants} of the distribution. For $\theta$ in the interior of the full canonical parameter space $\Theta$, the cumulant generating function corresponding to the canonical statistic is 
\begin{equation} \label{cgf}
  k_\theta(t) = c(t + \theta) - c(\theta),	
\end{equation}
  where $c(\theta)$ is the cumulant function corresponding to the exponential family in canonical form. The derivatives of $k_\theta(t)$ evaluated at 0 are the same as the cumulant function $c$ evaluated at $\theta$. The first and second cumulants of the canonical statistic are 
\begin{equation} \label{cumrel}
\begin{split}
	\nabla c(\theta) &= \E_\theta(Y) \\
	\nabla^2 c(\theta) &= \E_\theta(YY^T) - \left[\E_\theta(Y)\right]\left[\E_\theta(Y)\right]^T = \Var_\theta(Y).	
\end{split}
\end{equation}
In short, the mean and variance of the natural statistic always exist when $\theta$ is in the interior of the full canonical parameter space $\Theta$, and they are given by derivatives of the cumulant function.


\vspace{0.5cm}\noindent{\bf Verify that \eqref{cumrel} holds for the binomial, Poisson, and normal distriburions.}


\section*{Regular exponential families}


This property of having mean and variance of the canonical statistic given by derivatives of the cumulant function is so nice that families which have it for all $\theta$ are given a special name. An exponential family is regular if its full canonical parameter space \eqref{parmspace} is an open set so that the moment and cumulant generating functions exist for all $\theta$ and the formulas in the preceding section hold for all $\theta$. Nearly every exponential family that arises in applications is regular. We will not discuss non-regular exponential families.


\vspace{0.5cm}\noindent {\bf Example (Binomial distribution)}: The Binomial distribution with the standard parameter space $0 < p < 1$ written in canonical form is a regular full exponential family. To see this, the success probability $p$ has the parameter space $0 < p < 1$. The canonical parameter $\theta$ for this exponential family is $\theta = \log\left(\frac{p}{1-p}\right)$ and this implies that $c(\theta) < \infty$ for all $\theta \in \R$ and that $\Theta$ is open. \qed


\section*{Identifiability and directions of constancy}

In this section we will discuss geometric properties of exponential families. A statistical model is \emph{identifiable} if any two distinct parameter values correspond to distinct distributions.	An exponential family fails to be identifiable if there are two distinct canonical parameter values $\theta$ and $\psi$ such that the density \eqref{expodens} of one with respect to the other is equal to one with probability one. This happens if $Y^T(\theta - \psi)$ is equal to a constant with probability one. And this says that the canonical statistic $Y$ is concentrated on a hyperplane and the vector $\theta - \psi$ is perpendicular to this hyperplane.

Conversely, if the canonical statistic $Y$ is concentrated on a hyperplane
\begin{equation}\label{hyperplane}
  H = \{y : y^Tv = a\}	
\end{equation}
for some non-zero vector $v$, then for any scalar $s$ 
\begin{align*}
  c(\theta + sv) &= \log\left(\int e^{\inner{y, \theta + sv}}\lambda(dy)\right)	= sa + \log\left(\int e^{\inner{y,\theta}}\lambda(dy)\right) = sa + c(\theta),
\end{align*}
which immediately implies that
\begin{align*}
  l(\theta + sv) &= \inner{Y,\theta +sv} - c(\theta + sv) \\	
    &= \inner{Y,\theta} + s\inner{Y,v} - \left(sa + c(\theta)\right) \\
    &= \inner{Y,\theta} + sa - \left(sa + c(\theta)\right) \\    
    &= l(\theta).
\end{align*}
Therefore, we see that the canonical parameter vectors $\theta$ and $\theta + sv$ correspond to the same exponential family with probability equal to one for all $\theta \in \Theta$ when the canonical statistic is concentrated on a hyperplane \eqref{hyperplane}. We summarize this as follows.

\begin{thm}
An exponential family fails to be identifiable if and only if the canonical statistic is concentrated on a hyperplane. If that hyperplane is given by (8) and the family is full, then $\theta$ and $\theta+sv$ are in the full canonical parameter space and correspond to the same distribution for every canonical parameter value $\theta$ and every scalar $s$. 	
\end{thm}
 

The direction $sv$ along a vector $v$ in the parameter space such that $\theta$ and $\theta + sv$ always correspond to the same distribution is called a \emph{direction of constancy}. The theorem says that $v$ is such a vector if and only if $Y^Tv$ is constant with probability one. It is clear from this that the set of all such vectors is closed under vector addition and scalar multiplication, hence is a vector subspace. This subspace is called the \emph{constancy space} of the family. \vspace{0.5cm}

\noindent{\bf Note}: It is always possible to choose the canonical statistic and parameter so the family is identifiable. $Y$ being concentrated on a hyperplane means some components are affine functions of other components with probability one, and this relation can be used to eliminate components of the canonical statistic vector until one gets to an identifiable choice of canonical statistic and parameter. But this is not always advisable. Prematurely enforcing identifiability may complicate many theoretical issues.




\vspace*{0.5cm}\noindent{\bf Example (Multinomial distribution)}: We will show that the multinomial distribution is an exponential family and the usual vector statistic is canonical. To see this, let canonical parameter value $\psi$ correspond to the multinomial distribution with sample size $n$ and usual parameter vector $p$, and we find the exponential family generated by this distribution. Let $d$ denote the dimension of $y$ and $\theta$, let ${n \choose y}$ denote multinomial coefficients, and let $S$ denote the sample space of the multinomial distribution (vectors having nonnegative integer components that sum to $n$). 

In the vein of \eqref{Radon}, we obtain the identity
\begin{equation} \label{cumident}
	c(\theta) = c(\psi) + \log\left(\mathrm{E}_{\psi}\left(e^{\inner{Y, \theta - \psi}}\right)\right)
\end{equation}
Then \eqref{cumident} gives
\begin{align*}
  c(\theta) &= c(\psi) + \log\left(\mathrm{E}_{\psi}\left(e^{\inner{Y, \theta - \psi}}\right)\right) \\
  &= c(\psi) + \log\left(\sum_{y\in S} e^{\inner{y, \theta - \psi}}{n \choose y} \prod_{i=1}^d p_i^{y_i}\right) \\
  &= c(\psi) + \log\left(\sum_{y\in S} {n \choose y} \prod_{i=1}^d \left[p_ie^{\theta_i - \psi_i}\right]^{y_i}\right) \\  
  &= c(\psi) + n\log\left(\sum_{i=1}^d p_ie^{\theta_i - \psi_i}\right),
\end{align*}
where the last equality follows from the multinomial theorem. Then \eqref{Radon} gives
\begin{align*}
  f_{\theta}(y) &= f_{\psi}(y)e^{\inner{y,\theta-\psi} - c(\theta) + c(\psi)} \\
    &= {n \choose y} \left(\prod_{i=1}^d\left[p_ie^{\theta_i-\psi_i}\right]^{y_i}\right)\left(\sum_{i=1}^d p_ie^{\theta_i-\psi_i}\right)^{-n} \\
    &= {n \choose y} \prod_{i=1}^d \left(\frac{p_ie^{\theta_i-\psi_i}}{\sum_{j=1}^dp_je^{\theta_j-\psi_j}}\right)^{y_i}.
\end{align*}
We simplify the above by choosing $p$ and $\psi$ so that $p_ie^{-\psi_i} = 1$ for all $i$ and $c(\psi) = 0$, so
$$
  c(\theta) = n\log\left(\sum_{i=1}^d e^{\theta_i}\right)
$$
and
$$
  f_{\theta}(y) = {n \choose y}\prod_{i=1}^d \left(\frac{e^{\theta_i}}{\sum_{j=1}^d e^{\theta_j}}\right)^{y_i}
$$
and this is the PMF of the multinomial distribution with sample size $n$ and probability vector having components
$$
  p_i(\theta) = \frac{e^{\theta_i}}{\sum_{j=1}^d e^{\theta_j}}.
$$

This, however, is not an identifiable parameterization. The components of $y$ sum to $n$ so $Y$ is concentrated on a hyperplane to which the vector $(1,1, \cdots, 1)^T$ is perpendicular, hence by Theorem 1 a direction of constancy of the family. Eliminating a component of $Y$ to get an identifiability would destroy symmetry of formulas and make everything harder and messier. Best to wait until when (if ever) identifiability becomes absolutely necessary. \qed

\vspace{0.5cm}The Right Way\footnote{The Right Way is borrowed vernacular from Charles Geyer. The Right Way means anything that is not obviously the Wrong Way. There can be several Right Ways, and choosing among them can be subjective.} (IMHO) to deal with nonidentifiability, which is also called collinearity in the regression context, is the way the \texttt{R} functions \texttt{lm} and \texttt{glm} deal with it. (We will have to see how linear and generalized linear models relate to exponential families before this becomes fully clear, but I assure you this is how what they do relates to a general exponential family). When you find you have a non-identifiable parameterization, you have $Y^Tv$ constant with probability one. Pick any $i$ such that $v_i \neq 0$ and fix $\theta_i = 0$ giving a submodel that (we claim) has all the distributions of the original one (we have to show this).

For any parameter vector $\theta$ in the original model (with $\theta_i$ free to vary) we know that $\theta + sv$ corresponds to the same distribution for all $s$. Choose $s$ such that $\theta_i + sv_i = 0$, which is possible because $v_i  \neq 0$, hence we see that this distribution is in the new family obtained by constraining $\theta_i$ to be zero (and the other components of $\theta$ vary freely). 

This new model obtained by setting $\theta_i$ equal to zero is another exponential family. Its canonical statistic and parameter are just those of the original family with the $i$-th component eliminated. Its cumulant function is just that of the original family with the $i$-th component of the parameter set to zero. This new model need not be identifiable, but if not there is another direction of constancy and the process can be repeated until identifiability is achieved (which it must because the dimension of the sample space and parameter space decreases in each step and cannot go below zero, and if it gets to zero the canonical statistic is concentrated at a single point, hence there is only one distribution in the family, and identifiability vacuously holds).

This is what \texttt{lm} and \texttt{glm} do. If there is non-identifiability (collinearity), they report \texttt{NA} for some regression coefficients. This means that the corresponding predictors have been ``dropped'' but this is equivalent to saying that the regression coefficients reported to be \texttt{NA} have actually been constrained to be equal to zero.





\section*{Mean Value Parameterization}
The mean of the canonical statistic $\E_\theta(Y)$ is also a parameter. It is given as a function of the canonical parameter $\theta$,
\begin{equation} \label{mvp}
  \mu = \E_\theta(Y) = \nabla c(\theta) = g(\theta).	
\end{equation}
We will refer to $g(\theta)$ as the change-of-parameter map (or change-of-parameter) from canonical parameter $\theta$ to mean value parameter $\mu$.


\begin{thm} \label{thm-mvp}
For a regular full exponential family, the change-of-parameter from canonical to mean value parameter is invertible if the model is identifiable. Moreover both the change-of-parameter and its inverse are infinitely differentiable.
\end{thm}

%To prove the first part, let $\mu = g(\theta)$ for some $\theta$.
To prove this let $\mu$ be a possible value of the mean value parameter (that is, $\mu = g(\theta)$ for some $\theta$) and consider the function
\begin{equation}\label{h}
  h(\theta) = \inner{\mu,\theta} - c(\theta).	
\end{equation}
The second derivative of $h$ is $-\nabla^2c(\theta)$ which is equal to  $-\Var_\theta(Y)$, and this is a negative definite matrix ({\bf Why?}) %because $Y$ is not concentrated on a hyperplane. 
Hence \eqref{h} is a strictly concave function by Theorem 2.14 in  \cite{rockafellar2009variational}, and this implies that the maximum of \eqref{h} is unique if it exists by Theorem 2.6 in \cite{rockafellar2009variational}. Moreover, we know a solution exists because the derivative of \eqref{h} is
$
  \nabla h(\theta) = \mu - \nabla c(\theta),
$
and we specified that $\mu = \nabla c(\theta)$ for some $\theta$.
%Moment generating functions are infinitely differentiable at zero. Hence so are cumulant generating functions because the logarithm function is in- finitely differentiable. Hence cumulant functions are infinitely differentiable on the interior of the full canonical parameter space. Hence the change-of- parameter (9) is infinitely differentiable.

{\bf Show that cumulant functions are infinitely differentiable and are therefore continuously differentiable.} Now we see that the Jacobian matrix of the change-of-parameter is 
$$
  \nabla g(\theta) = \nabla^2 c(\theta)
$$
which we (you) have already shown is nonsingular. The inverse function theorem (Browder, 1996, Theorems 8.15 and 8.27) thus says that $g$ is locally invertible, and the local inverse must agree with the global inverse which we have already shown exists. The inverse function theorem goes on to state that the derivative of the inverse is the inverse of the derivative
$$
  \nabla g^{-1}(\theta) = \left[\nabla g(\theta)\right]^{-1}, \qquad \text{when} \; \mu = g(\theta) \; \text{and} \; \theta = g^{-1}(\mu).
$$
{\bf Now show that $g^{-1}(\theta)$ is infinitely differentiable.}




\section*{Multivariate Monotonicity}
A mapping from $g : \R^d \to \R^d$ is multivariate monotone (Rockafellar and Wets, 1998, Definition 12.1) if
\begin{equation} \label{multimono}
  \left[g(x_1) - g(x_2)\right]^T(x_1 - x_2) \geq 0, \qquad \text{for} \; x_1 \; \text{and} \; x_2 \in \R^d,	
\end{equation}
and strictly multivariate monotone if \eqref{multimono} holds with strict inequality whenever $x_1 \neq x_2$. If $g$ is differentiable, then by Proposition 12.3 in \cite{rockafellar2009variational} it is multivariate monotone if and only if the symmetric part of the Jacobian matrix $\nabla g$ is positive-semidefinite for each $x$. A sufficient but not necessary condition for $g$ to be strictly multivariate monotone is that the symmetric part of $\nabla g$ be positive definite for each $x$.

Let $g$ be the change-of-parameters mapping from canonical to mean value parameters \eqref{mvp} then we showed in the previous section that its Jacobian matrix is positive semidefinite in general and strictly positive definite when the model is identifiable. Thus this change-of-parameter is multivariate monotone in general and strictly multivariate monotone when the model is identifiable.

Thus, if $\mu_1$ corresponds to $\theta_1$ and $\mu_2$ to $\theta_2$, we have
\begin{equation} \label{multiparm}
  (\mu_1 - \mu_2)^T(\theta_1 - \theta_2) > 0, \qquad \text{whenever} ; \theta_1 \neq \theta_2.	
\end{equation}
In general, this is all we can say about the map from canonical to mean value parameters. However, there is a casual version of \eqref{multiparm} which eases interpretation. If we rewrite \eqref{multiparm} using subscripts
$$
  \sum_{i=1}^d(\mu_{1i} - \mu_{2i})(\theta_{1i} - \theta_{2i}) > 0
$$
and consider $\theta_1$ and $\theta_2$ that differ in only one coordinate, say the $k$th, then we get
$$
  (\mu_{1k} - \mu_{2k})(\theta_{1k} - \theta_{2k}) > 0,
$$
which says \emph{if we increase one component of the canonical parameter vector, leaving the other components fixed, then the corresponding component of the mean value parameter vector also increases, and the other components can go any which way}. This is easier to explain than the full multivariate monotonicity property, but is not equivalent to it. The casual property is not enough to make some arguments about exponential families that are needed in applications (for example in the Appendix of Shaw and Geyer, 2010).

Here is another rewrite of \eqref{multiparm} that preserves its full force. Fix a vector $v \neq 0$. Write $\theta_2 = \theta$ and $\theta_1 = \theta + sv$, so multivariate monotonicity \eqref{multimono} becomes 
$$
  \left[g(\theta + sv) - g(\theta)\right]^Tv > 0, \qquad \text{for} \; s \neq 0.
$$
Differentiate with respect to $s$ and set $s = 0$, which gives the so-called directional derivative of $g$ in the direction $v$ at the point $\theta$
\begin{equation} \label{directderiv}
  \nabla g(\theta; v) = v^T\left[\nabla g(\theta)\right]v = v^T\left[\nabla^2 c(\theta)\right]v.
\end{equation}
We know that $\nabla^2 c(\theta)$ is positive semi-definite in general and strictly positive definite when the model is identifiable. Hence we see (again) that the $\theta$ to $\mu$ mapping is multivariate monotone in general and strictly multivariate monotone when the model is identifiable.

Partial derivatives are special cases of directional derivatives when the vector $v$ points along a coordinate direction (only one component of $v$ is nonzero). So the casual property only says that all the partial derivatives are nonzero and this corresponds to asserting \eqref{directderiv} with $v$ being along coordinate directions, and this is equivalent to asserting that the diagonal components of $\nabla^2 c(\theta)$ are positive. And now we clearly see how the casual property is indeed casual. It only asserts that the diagonal elements of $\nabla^2 c(\theta)$ are positive, which is far from implying that $\nabla^2 c(\theta)$ is a positive definite matrix.


\section*{Maximum likelihood estimation}

The derivative of the log likelihood is 
$$
  \nabla l(\theta) = y - \nabla c(\theta).
$$
The second derivative is 
$$
  \nabla^2 l(\theta) = -\nabla^2 c(\theta).
$$
Hence observed and expected Fisher information for the canonical parameter vector $\theta$ are the same
\begin{equation} \label{FI}
	I(\theta) = \nabla^2 c(\theta).
\end{equation}
Fisher information measures the expected curvature of the log likelihood around the true parameter value. If the likelihood is sharply curved around $\theta$ -- the expected information $I(\theta)$ is large -- then a small change in $\theta$ can lead to a drastic decrease in the likelihood. Conversely, if $I(\theta)$ is small then small changes in $\theta$ will not affect the likelihood that much. These heuristics are important when we cover separation and non-identifiability. 


When the model is identifiable, the canonical statistic vector $Y$ is not concentrated on a hyperplane, the second derivative is negative definite everywhere, hence the log likelihood is strictly concave, hence the maximum likelihood estimate is unique if it exists. Thus,
\begin{align*}
  y &= \nabla c(\hat{\theta}), \\
  \hat{\theta} &= g^{-1}(y).
\end{align*}

\vspace{0.5cm}\noindent {\bf Derive the MLEs of the canonical parameters of the binomial, Poisson, and normal distributions.}



\subsection*{Non-Existence of the MLE}

Unlike our proof of Theorem 2 in Section 1.10, where we assumed the existence of a solution, we cannot prove the maximum likelihood estimate (for the canonical parameter) exists. Consider the binomial distribution. The MLE for the usual parameterization is $\hat p = y/n$. The canonical parameter is $\theta = \text{logit}(p)$. But $\hat \theta = \text{logit}(\hat p)$ does not exist when $\hat p = 0$ or $\hat p = 1$, which is when we observe zero successes or when we observe $n$ successes in $n$ trials.

One might think the lesson to draw from this is not to use the canonical parameterization, but it turns out that generalized linear models and log-linear models for categorical data and other applications of exponential families always use the canonical parameterization for many reasons. Hence we have to deal with possible non-existence of the MLE. We will revisit this topic when we discuss GLMs.


\subsection*{Observed equals expected}

For a regular full exponential family, the MLE cannot be on the boundary of the canonical parameter space (regular means the boundary is empty), and the MLE, if it exists, must be a point where the first derivative is zero, that is, a $\theta$ that satisfies
$$
  y = \nabla c(\theta) = \E_\theta(Y).
$$
The MLE is the (unique if the model is identifiable) parameter value that makes the observed value of the canonical statistic equal to its expected value. We call this the {\bf \emph{observed equals expected}} property of maximum likelihood in exponential families. This property is even simpler to express in terms of the mean value parameter. By invariance of maximum likelihood under change-of-parameter, the MLE for $\mu$ is 
$$
  \hat\mu = \nabla c(\hat\theta)
$$
and the observed equals expected property is therefore
\begin{equation} \label{obsequalsexp}
  y = \hat\mu.	
\end{equation}


\section*{Independent and Identically Distributed}

Suppose $y_1, \ldots, y_n$ are independent and identically distributed (IID) from some distribution in an exponential family (unlike our notation in the preceding section, $y_i$ are not components of the canonical statistic vector but rather IID realizations of the canonical statistic vector, so each $y_i$ is a vector). The log likelihood for sample size $n$ is
\begin{equation} \label{iid}
	l_n(\theta) = \sum_{i=1}^n\left[\inner{y_i,\theta} - c(\theta)\right] 
	  = \inner{\sum_{i=1}^n y_i, \theta} - n c(\theta),
\end{equation}
and we see that the above log likelihood is an exponential family with 
\begin{itemize}
 \item canonical statistic $\sum_{i=1}^n y_i$,
 \item cumulant function $\theta \mapsto n c(\theta)$, and
 \item canonical parameter $\theta$ and full canonical parameter space $\Theta$ the same as the originally given family from which every observation is a member.
\end{itemize}
Thus IID sampling gives us a new exponential family, but still an exponential family.


\section*{Asymptotics of Maximum Likelihood}

Rewrite \eqref{iid} as 
$$
  l_n(\theta) = n\left[\inner{\bar y_n, \theta} - c(\theta)\right]
$$
so that
$$
  \nabla l_n(\theta) = n\left[\bar y_n - \nabla c(\theta)\right].
$$
From which we see that for an identifiable regular full exponential family where the MLE must be a point where the first derivative is zero, we can write
\begin{align*}
  	\nabla l_n(\theta) = n\left[\bar y_n - \nabla c(\theta)\right] &= 0, \\
  	\bar y_n - \nabla c(\hat\theta) &= 0, \\
  	\bar y_n &= \nabla c(\hat\theta).
\end{align*}
Recall the change-of-parameters mapping $g:\theta \mapsto \mu$ given by \eqref{mvp} in the mean value parameters section. We can write
\begin{equation} \label{MVPg}
  \hat\theta_n = g^{-1}(\bar y_n).	
\end{equation}
More precisely, \eqref{MVPg} holds when the MLE exists (when the MLE does not exist, $\bar y_n$ is not in the domain of $g^{-1}$, which is in the range of $g$).
 
By the multivariate central limit theorem (CLT)
$$
  \sqrt{n}\left(\bar y_n - \mu\right) \to N\left(0, I(\theta)\right)
$$
and we know that $g^{-1}$ is differentiable (Theorem~\ref{thm-mvp}) with the derivative given by 
$$
  \nabla g^{-1}(\theta) = \left[\nabla g(\theta)\right]^{-1}, \qquad \text{where} \; \mu = g(\theta) \; \text{and} \; \theta = g^{-1}(\mu).
$$
So the usual asymptotics of maximum likelihood
\begin{equation} \label{asymptoticsMLE}
	\sqrt{n}\left(\hat\theta_n - \theta\right) \to N\left(0, I(\theta)^{-1}\right)
\end{equation}
is just the multivariate delta method applied to the multivariate CLT.

%For details see the 8112 notes (Geyer, 2013). In fact, Theorem 10 in those notes asserts a slightly stronger conclusion, that (20) holds for every identifiable full exponential family, whether or not it is regular, so long as the true unknown parameter θ is in the interior of the canonical parameter space.
%In summary, one “regularity condition” for (20) to hold is that we have an identifiable regular full exponential family. Of course, (20) holds for many non-exponential-family models, but the regularity conditions are so complicated that they are often hard to verify. In exponential families the verification is trivial: the usual asymptotics of maximum likelihood always works.


\section*{Finite sample concentration of MLE}

The previous section is devoted to large sample properties of maximum likelihood estimation within the context of regular full exponential families. These properties are especially relevant for statistical inference. MLEs of parameters in regular full exponential families also possess desirable finite sample properties. We first motivate the concept of sub-Gaussian and sub-exponential random variables which represent classes of desirable tail behavior for statistical models. The following definitions come from \cite{wainwright2019high}:

\begin{defn}
A random variable $Y$ with mean $\mu = \E(Y)$ is \emph{sub-Gaussian} if there exists a positive number $\lambda$ such that 
$$
  E\left(e^{\phi(Y - \mu)}\right) \leq e^{\lambda^2\phi^2/2} 
    \qquad \text{for all} \; \phi \in \R.
$$	
\end{defn}


\begin{defn}
A random variable $Y$ with mean $\mu = \E(Y)$ is \emph{sub-exponential} if there exist non-negative numbers $(\lambda,b)$ such that 
$$
  E\left(e^{\phi(Y - \mu)}\right) \leq e^{\lambda^2\phi^2/2} 
    \qquad \text{for all} \; |\phi| < 1/b.
$$	
\end{defn}


Let $Y$ be a univariate regular full exponential family with canonical parameter $\theta$ and \textbf{show that $Y$ is sub-exponential}. Now let $\hat\theta$ be the MLE for the canonical parameter $\theta$. We now show that the MLE of an exponential family obeys sub-exponential concentration. Consider a Taylor expansion of the score function of an exponential family evaluated at the MLE
\begin{align*}
  0 = \nabla l_n(\hat\theta) &= \nabla l_n(\theta) 
    + \nabla^2l_n(\theta)(\hat\theta - \theta) + R_n	\\
    &= \sum_{i=1}^n\{y_i - \nabla c(\theta)\} + \nabla^2l_n(\theta)(\hat\theta - \theta) + R_n,
\end{align*}
where $R_n = o_P(n^{-1/2})$. Notice that $\sum_{i=1}^n\{y_i - \nabla c(\theta)\}$ is a sum of mean zero sub-exponential random variables, and is also sub-exponential \citep[Chapter 2]{wainwright2019high}. Furthermore, the negative and/or a scalar products of $\sum_{i=1}^n\{y_i - \nabla c(\theta)\}$ are also sub-exponential. After rearranging terms in the above displayed equation we see that 
$$
  (\hat\theta - \theta) = -\{\nabla^2 l_n(\theta)\}^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\} + \widetilde R_n,
$$
where $\widetilde R_n = -\{\nabla^2l_n(\theta)\}^{-1}R_n = o_P(n^{-1/2})$. Putting all of this together yields
$$
  \Prob\left( (\hat\theta - \theta) \geq t\right) 
  = \Prob\left( -\{\nabla^2l_n(\theta)\}^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\} \geq t - \widetilde R_n\right),
$$
where $t > 0$. Handwaving slightly, there exists a number $A > 0$ such that, for $n$ large, 
\begin{align*}
  &\Prob\left( -\{\nabla^2l_n(\theta)\}^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\} \geq t - \widetilde R_n \right) \\
  &= \Prob\left( -\{n^{-1}\nabla^2l_n(\theta)\}^{-1}\left(n^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\}\right) \geq t - \widetilde R_n\right) \\
  &\leq \Prob\left( -An^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\} \geq t\right).
\end{align*}
Page 29 in \cite{wainwright2019high} implies that, for the sub-exponential variable $-An^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\}$, we have parameters $(\lambda,b)$ such that
$$
  \Prob\left( -An^{-1}\sum_{i=1}^n\{y_i - \nabla c(\theta)\} \geq t\right) 
    \leq 
\left\{\begin{array}{cl}
    \exp\left(-\frac{nA^2t^2}{2\lambda^2}\right), & \text{for} \; 0 \leq t \leq \frac{\lambda^2}{nAb}, \\
    \exp\left(-\frac{nAt}{2b}\right), & \text{for} \; t > \frac{\lambda^2}{nAb}.
\end{array}	
\right.
$$
We can therefore conclude that the MLE of $\theta$ exhibits sub-exponential concentration following the logic that $(\hat\theta - \theta)$ has the same tail bounds as a sub-exponential random variable. We can use these results to obtain the rate of convergence
$$
  \Prob\left( (\hat\theta - \theta) \geq \frac{\log(n)}{n}\right) 
    = O\left(n^{-\frac{A}{2b}}\right),
$$
where $t = \log(n)/n$.



\section*{Canonical linear submodels: intro to GLMs}

We now motivate generalized linear models (GLMs) within the context of exponential theory. We will not yet discuss specific examples of GLMs or extensions beyond canonical representations. We first present canonical affine submodels of an exponential family. A canonical affine submodel of an exponential family is a submodel having parameterization
$$
  \theta = a + M\beta
$$
where $\theta \in \R^n$ is the canonical parameter vector corresponding to the original exponential family, $\beta \in \R^p$ is the canonical parameter vector for the submodel, $a$ is known offset vector, and $M$ is a known matrix. The matrix $M$ is usually called the \emph{model matrix} in the terminology used by the \texttt{R} functions \texttt{lm} and \texttt{glm}. The vector $a$ is called the offset vector in the terminology used by the \texttt{R} functions \texttt{lm} and \texttt{glm}. In most applications the offset vector is not used giving parameterization 
$$
  \theta = M\beta,
$$  
in which case we say the submodel is a \emph{canonical linear submodel}. We will restrict attention to the canonical linear submodel. The canonical linear submodel log likelihood is given by
\begin{equation} \label{subloglike}
\begin{split}
  l(\theta) &= \inner{y,\theta} - c(\theta) \\
    &= \inner{y,M\beta} - c(M\beta) \\
    &= \inner{M^Ty,\beta} - c(M\beta), 	
\end{split}
\end{equation}
and we see that we again have an exponential family with
\begin{itemize}
	\item canonical statistic $M^Ty$,
	\item cumulant function $\beta \mapsto c(M\beta)$, and 
	\item submodel canonical parameter vector $\beta$.
\end{itemize}
If $\theta$ varies freely (over a whole vector space), then $\beta$ also varies freely (over a whole vector space of lower dimension, $p \leq n$). But if the originally given full canonical parameter space was $\Theta$, then the full submodel canonical parameter space is 
$$
  B = \{\beta : M\beta \in \Theta\}.
$$
Thus a canonical linear submodel gives us a new exponential family, with lower-dimensional canonical parameter and statistic. The submodel exponential family is full if the original exponential family was full. Notice that $\theta$ and $B$ are defined through the column space of $M$, not the particular model matrix $M$, the particular $\beta$ value does not determine the submodel uniquely.


To distinguish between the submodel and the originally given exponential family, we often call the latter the \emph{saturated model}. Now we have four parameters: the saturated model canonical and mean value parameters $\theta$ and $\mu$ and the canonical linear submodel canonical and mean value parameters $\beta$ and $\tau = M^T\mu$. Relations between these parameterizations are given in Figure~\ref{Fig1:parameterizations}. 

The observed equals expected property for the submodel is
\begin{equation} \label{submodelmvp}
	\hat\tau = M^T\hat\mu = M^Ty.
\end{equation}
We cannot actually solve these equations for $\hat\mu$ because the mapping $\mu \to M^T\mu$ is usually not one-to-one (the $n > p$ case where $M \in \R^{n \times p}$ and is full column rank). Hence we cannot determine $\hat\theta$ and $\hat\beta$ from them either. The only way to determine the MLE is to maximize the log likelihood \eqref{subloglike} for $\beta$ to obtain $\hat\beta$ and then $\hat\theta = M\hat\beta$ and $\hat\mu = \nabla c(\hat\theta)$ and $\hat\tau = M^T\hat\mu$. But the observed equals expected property is nevertheless very important. %It is the only simple property of maximum likelihood that can be used in interpretation of exponential families (more on this later).

\vspace{0.5cm}\noindent{\bf Derive the asymptotic distribution for the MLE of $\hat{\beta}$ and $\hat{\tau}$.}

\vspace{0.5cm}Recall that the saturated model canonical parameter vector $\theta$ is ``linked'' to the saturated model mean value parameter vector through the change-of-parameter mappings $g(\theta)$. We can reparameterize $\theta = M\beta$ and write
$$
 \E_\theta(Y) = \mu = g(M\beta) 
$$
which implies that we can write
$$
  g^{-1}\left(\E_\theta(Y)\right) = M\beta.
$$
Therefore, a linear function of the canonical submodel parameter vector is linked to the mean of the exponential family through the inverse change-of-parameter mapping $g^{-1}$. This is the basis of exponential family generalized linear models with link function $g^{-1}$. Note that most treatments of GLMs will present $g$ as the link function. Instead we motivated $g$ as the change of parameters mapping from canonical to mean-value parameters. 


%A concise presentation of the various model parameterizations and how they are related to each other is given in Figure~\ref{Fig1:parameterizations}.






\begin{figure}[t]
\begin{center}
\begin{tikzpicture}[descr/.style={fill=white},text height=1.5ex, text depth=0.25ex]
\node (a) at (0,0) {$\theta$};
\node (b) at (4,0) {$\beta$};
%\node (c) at (8,0) {$\beta$};
\node (c) at (0,-4) {$\mu$};
\node (d) at (4,-4) {$\tau$};
%\node (f) at (8,-4) {$\tau$};
\path[->,font=\scriptsize]
([yshift= -5pt]b.west) edge node[below] {$\theta = M\beta$} ([yshift= -5pt]a.east)
([yshift=  5pt]a.east) edge node[above] {} ([yshift= 5pt]b.west)
([xshift=  5pt]a.south) edge node[right] {$\mu = \nabla c(\theta)$} ([xshift= 5pt]c.north)
([xshift= -5pt]c.north) edge node[right] {} ([xshift= -5pt]a.south)
([xshift= -5pt]d.north) edge node[left] {} ([xshift= -5pt]b.south)
([xshift=  5pt]b.south) edge node[right] {$\tau = \nabla_{\beta}c(M\beta)$} ([xshift= 5pt]d.north)
([yshift=  5pt]c.east) edge node[above] {$\tau = M^T\mu$} ([yshift= 5pt]d.west)
([yshift= -5pt]d.west) edge node[below] {} ([yshift= -5pt]c.east)
\end{tikzpicture}
\end{center}
\caption{A depiction of the transformations necessary to change between parameterizations. Arrows going in opposite directions specify transformations and their inverses. $M$ is a known model matrix of full column rank, and $c$ is the cumulant function for the exponential family model.}\label{Fig1:parameterizations}
\end{figure}

\section*{Inference}

Recall that the canonical submodel log likelihood \eqref{subloglike} takes the form
$$
	l(\beta) = \inner{M^Ty,\beta} - c(M\beta)
$$
when the offset is ignored. From invariance of maximum likelihood estimation derived in \eqref{asymptoticsMLE} or direct arguments, we have that the asymptotic distribution of the MLE $\hat\beta$ takes the form
$$
  \sqrt{n}\left(\hat\beta - \beta\right) \overset{d}{\to} N(0, \Sigma^{-1})
$$
where $\Sigma = \E\left(-\nabla^2 l(\beta)\right)$ is the Fisher information matrix corresponding to the canonical linear submodel.


\subsection*{Wald inference}

Let $\widehat\Sigma$ be estimated $\Sigma$ using the MLE $\hat\beta$ in place of $\beta$. In particular, the $j$th element $\hat\beta_j$ of $\hat\beta$ is asymptotically normal with asymptotic variance
$$
  \widehat{\Var}(\hat\beta_j) = jth \; \text{diagonal element of} \; \widehat\Sigma.
$$
The Wald $Z$ statistic for testing $H_o:\beta_j = \beta_{jo}$ is 
$$
  z_W = \frac{\hat\beta_j - \beta_{jo}}{\text{se}(\hat\beta_j)} \quad \overset{H_o}{\sim} \quad N(0,1)
$$
where se$(\hat\beta_j) = \sqrt{\widehat{\Var}(\hat\beta_j)}$. We can construct $(1-\alpha)\times 100\%$ Wald based confidence intervals of the form
$$
  \hat\beta_j \pm z_{\alpha/2}\text{se}(\hat\beta_j)
$$
for some error tolerance $0 < \alpha < 1$.


\subsection*{Deviance, Goodness of Fit, and likelihood ratios}

To motivate the deviance of a statistical model we will revisit the mean-value parameter vector $\mu$ and rewrite the log likelihood in the notation of this parameterization as $l(\mu;y)$. From the observed equals expected property we have that the unrestricted MLE of $\mu$ is $y$. Now consider a canonical submodel (GLM) of the form $\theta = M\beta$. Let $\hat\mu$ be the MLE of $\mu$ restricted to an identifiable canonical submodel ($\hat{\mu} = \nabla c(\hat\theta)$ where $\hat\theta = M\hat\beta$). It follows that
$$
  l(y;y) \geq l(\hat\mu; y).
$$
We refer to the unrestricted case, in which each observation has its own mean ($\hat\mu = y$), is called the \emph{saturated model}.

With all of this in mind, the \emph{deviance} of the GLM is
$$
  D(y;\hat\mu) = -2\left(l(\hat\mu;y) - l(y;y)\right).
$$
We see that the deviance statistic is a function of a ratio of two likelihoods, one corresponding to the canonical submodel and one corresponding to the saturated model. The deviance statistic has approximate distribution
$$
  D(y;\hat\mu) \; \overset{H_o}{\sim} \; \chi^2_{\text{df}}
$$
where $H_o$ is that the canonical submodel is correct and the alternative test is that the canonical submodel is incorrect but the saturated model is correct, df = $n - p$, $n$ is the sample size, and $p$ is the number of parameters in the canonical submodel. So we reject correctness of the canonical submodel when
$$
  D(y;\hat\mu) \; > \: \chi^2_{\text{df}}(\alpha).
$$
(Note that the $\chi^2$ approximation can be poor.)


\vspace*{0.5cm} We can use deviance based testing to nested models. Let $\mathcal{M}_0$ and $\mathcal{M}_1$ both be canonical submodels. We say that $\mathcal{M}_0$ is \emph{nested} within $\mathcal{M}_1$  when every distribution in $\mathcal{M}_0$ is also in $\mathcal{M}_1$ but not vice-versa. That is, $\mu$ is more restricted under $\mathcal{M}_0$ than under $\mathcal{M}_1$. Let $\hat\mu_0$ be the MLE of $\mu$ under $\mathcal{M}_0$, and let $\hat\mu_1$ be the MLE of $\mu$ under $\mathcal{M}_1$. We can use this framework for testing
$$
  H_0:\mathcal{M}_0 \; \text{true} \qquad H_a:\mathcal{M}_1 \; \text{true, but not} \; \mathcal{M}_0
$$
using the likelihood ratio $\chi^2$ statistic given by 
\begin{align*}
 -2\left[l(\hat\mu_0;y) - l(\hat\mu_1;y)\right] &= -2\left[l(\hat\mu_0;y) - l(y;y)\right] 
   - \left\{-2\left[l(\hat\mu_1;y) - l(y;y)\right]\right\} \\
   &= D(y;\hat\mu_0) - D(y;\hat\mu_1) \\ 
   &\approx \chi^2_{\text{df}},	
\end{align*}
where df = $p_1 - p_0$, $p_1$ is the number of parameters in $\mathcal{M}_1$, and $p_0$ is the number of parameters in $\mathcal{M}_0$. (Note that the $\chi^2$ approximation is often adequate here even it isn't adequate for the saturated model provided that $\mathcal{M}_1$ is not too close to saturated.)

%\subsection*{Profile Likelihood}

%We can construct a $(1-\alpha)\times 100\%$ confidence interval directly from the log likelihood. 




\section*{Optimization}

In this section we discuss optimization routines for estimating parameters in canonical exponential family linear submodels. The goal will be to find 
\begin{equation} \label{optim}
  \text{argmax}_{\beta} l(\beta) 
    \quad = \quad \text{argmax}_{\beta}\left[\inner{M^Ty,\beta} - c(M\beta)\right]
\end{equation}
in identifiable models. Note that we will blend our notation with the notation in Chapter 4 of \cite{agresti2013cat} when we define the Newton-Raphson, Fisher scoring, and IRLS algorithms.

\vspace*{0.5cm}\noindent{\bf Newton-Raphson method}: A classic algorithm for handling iterative solutions of nonlinear systems of equations is the \emph{Newton-Raphson algorithm}. This algorithm begins with an initial guess $\beta_0$ for the solution. It obtains a second guess by approximating the function to be maximized in a neighborhood of the initial guess by a second-degree polynomial and then finding the location of the polynomial's maximum value. This process is repeated iteratively until the discrepancy in successive evaluations of the objective function evaluate along the sequence of iterates is smaller than some convergence threshold. The sequence of iterates that this algorithm generates converge to a solution $\hat\beta$ when the optimization function is suitable (full rank properly conditioned Fisher Information matrix) and/or the initial guess is good.

We now explain the Newton-Raphson algorithm formally. Let $U(\beta) = \nabla l(\beta)$ be the score function corresponding to the log likelihood canonical linear exponential family submodel, and let $H(\beta) = \nabla^2 l(\beta)$ denote the Hessian matrix. At iteration $k$, consider the following second order Taylor series approximation of $l(\beta)$,
\begin{equation} \label{NR}
  l(\beta) \approx l(\beta_k) + U(\beta_k)^T(\beta - \beta_k) 
    + \frac{(\beta-\beta_k)^TH(\beta_k)(\beta - \beta_k)}{2}.
\end{equation}
Now solving
$$
  U(\beta) \approx U(\beta_k) + H(\beta_k)(\beta - \beta_k) = 0
$$
for $\beta$ yields the next guess. That guess is
\begin{equation} \label{NRupdates}
	\beta_{k+1} = \beta_k - H(\beta_k)^{-1}U(\beta_k).
\end{equation}
This algorithm is locally fast, exhibits quadratic convergence, provided that it converges. Convergence is likely in identifiable models where $H(\beta_{0})$ is positive definite. However, the Newton-Raphson method can be quite sensitive to the choice of starting values $\beta_{0}$. 

For many identifiable GLMs, including Poisson models with log link and binomial models with logit link, with full rank model matrices the Hessian is negative definite and the log likelihood is a strictly concave function. The maximum likelihood estimators of model parameters exist and are unique under quite general conditions \citep{wedderburn1976existence}.


\vspace*{0.5cm}\noindent{\bf Fisher scoring algorithm}: The \emph{Fisher scoring algorithm} is an alternative method for solving systems of equations. It resembles the Newton-Raphson algorithm, the distinction being with the Hessian matrix used in the Newton updates. Fisher scoring uses the expected Fisher information matrix instead of the Hessian which is the observed Fisher information matrix. 

We will let $\Hcal$ be the expected information matrix so that $\Hcal(\beta) = -\E\left\{\nabla^2 l(\beta)\right\}$. The Newton update step for the Fisher scoring method is 
$$
  \beta_{k+1} = \beta_k + \left\{\Hcal(\beta_k)\right\}^{-1} U(\beta_k).
$$
or
\begin{equation} \label{eq:FS}
  \Hcal(\beta_k)\beta_{k+1} = \Hcal(\beta_k)\beta_k + U(\beta_k).
\end{equation}
The chain rule and an appeal to Figure~\ref{Fig1:parameterizations} allows us to write $\Hcal(\beta) = M^TW(\beta)M$ where 
$$
  W(\beta) = \left\{\nabla_\theta^2 c(\theta^*)\right\}|_{\theta^* = M\beta}.
$$
The estimated asymptotic covariance matrix $\Hcal^{-1}$ of $\hat{\beta}$ occurs as a by-product of this algorithm as $\left\{\Hcal(\beta_k)\right\}^{-1}$ where $k$ is an iteration number at which convergence is deemed to have occurred. 

\vspace*{0.5cm}

For both Fisher scoring and Newton-Raphson, the score function $U(\beta)$ can be written as
$$
  U(\beta) = \nabla l(\beta) = M^T\left\{Y - \nabla_\theta c(\theta^*)|_{\theta^* = M\beta}\right\}. 
$$

For GLMs with canonical link (the entirety of these notes), we have that the observed and expected information are the same. This is a consequence of the observed equals expected property $\hat{\mu} = y$ that is noted above. For noncanonical link models (which we see later), Fisher scoring has the advantages that it produces the asymptotic covariance matrix as a by-product, the expected information is necessarily nonnegative definite, and as seen next, it is closely related to weighted least-squares methods for ordinary linear models. However, it need have second-order convergence, and for complex models the observed information is often easier to calculate.


\vspace*{0.5cm}\noindent{\bf IRLS algorithm}: A relation exists between \emph{weighted least-squares estimation} and using the Fisher scoring algorithm to find MLEs. We refer here to the general linear model of the form 
$$
  Z = M\beta + \varepsilon,
$$
where $V$ be the covariance matrix of $\varepsilon$. The weighted least-squares (WLS) estimator of $\beta$ is 
$$
  \hat\beta_{\text{WLS}} = \left(M^TV^{-1}M\right)^{-1}M^TV^{-1}Z.
$$

We will now motivate the iterative (re)weighted least squares algorithm for estimation of the submodel canonical parameter vector $\beta$. Recall that $\Hcal(\beta) = M^TW(\beta)M$ and note that we can write the score function $U(\beta)$ as 
$$
  U(\beta) = M^T W(\beta) W^{-1}(\beta)(y - \mu(\beta)), 
$$
%where $D(\beta)$ is a diagonal matrix having elements $\partial\mu_i/\partial (x_i^T\beta)$. 
Now, noting the right hand side of \eqref{eq:FS},
\begin{align*}
	\Hcal(\beta)\beta + U(\beta) &= (M^TW(\beta)M)\beta + M^TW(\beta) W^{-1}(\beta)(y - \mu(\beta)) \\
	&= M^T W(\beta)\left[M\beta + W^{-1}(\beta)(y - \mu(\beta))\right] \\
	&= M^T W(\beta) z(\beta).
\end{align*}
Another referral to \eqref{eq:FS} gives
$$
  \Hcal(\beta_k)\beta_{k+1} = M^T W(\beta_k) z(\beta_k) 
  \qquad \implies \qquad 
  (M^TW(\beta_k)M)\beta_{k+1} = M^T W(\beta_k) z(\beta_k).
$$
The above equation has a solution of the form
$$
  \beta_{k+1} = (M^TW(\beta_k)M)^{-1}M^T W(\beta_k) z(\beta_k), 
$$
where 
\begin{itemize}
	\item the "response" is $z(\beta) = M\beta + W^{-1}(\beta)(y - \mu(\beta))$
	\item $\mu(\beta)$ is the mean value parameter defined as a function of $\beta$
%	\item $D(\beta)$ is a diagonal matrix having elements $\partial\mu_i/\partial (x_i^T\beta)$
\end{itemize}
Note that although we follow a similar notation as \cite{agresti2013cat}, our algorithm and our $W(\beta)$ quantity is slightly different than that in \cite{agresti2013cat}.


%The \texttt{glm} function solves \eqref{optim} using the iteratively reweighted least squares (IWLS) algorithm. The IWLS algorithm is used to minimize objective functions in the form of a $p$-norm:
%$$
%  \text{argmin}_{\beta} \sum_{i=1}^n |y_i - f_i(\beta)|^p,
%$$
%through iterations which update as
%$$
%  \beta_{k+1} = \text{argmin}\sum_{i=1}^n w_i(\beta_k)|y_i - f_i(\beta)|^p.
%$$
%When $p = 2$ and the function $f$ is linear, the IWLS objective function and the update step reduce to the least squares problem. In this setting,
%$$
%  \beta_{k+1} = \text{argmin}\sum_{i=1}^n w_{i,k}|y_i - X_i\beta|^2
%    = \left(X^TW_kX\right)^{-1}X^TW_ky,
%$$
%where $W_k$ is a diagonal matrix of weights and updated as 
%$$
%  w_{i,k} = |y_i - X_i\beta_k|
%$$


%\subsection*{Other algorithms}
%For a full family in mean value parameterization the MLE is explicitly given by $\hat{\mu} = y$ as stated in \eqref{obsequalsexp}. For other parameterizations outlined in Figure~\ref{Fig1:parameterizations} we must invert the system of equations $\mu(\hat \Psi) = y$ where $\hat\Psi$ is a MLE for any one of the other parameterizations.



\vspace*{0.5cm}\noindent{\bf Quasi-Newton methods}: Quasi-Newton methods are modifications of \eqref{NRupdates}, where the $J$ matrix is approximated (by the secant method for example), typically because an explicit formula for $J$ is not available. One such Quasi-Newton method is the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm for solving unconstrained nonlinear optimization problems. We present the steps for the BFGS algorithm in our optimization context \eqref{optim} where $l$ is a differentiable scalar function. 

The algorithm begins at a user-specified initial value (initial estimate for the optimal value) $\beta_{k=0}$ and an initial guess $B_0$. Then proceed iteratively to get a better estimate of $\beta$ at each stage. The steps are:
\begin{enumerate}
	\item Obtain a direction $x_k$ by solving $B_kx_k = \nabla_\beta l(\beta_k)$.
	\item Perform a one-dimensional optimization (line search) to find an acceptable stepsize $\alpha_k$ to be made in the direction $x_k$, so that $x_k = \text{arg min} -l(\beta_k + \alpha x_k)$.
	\item Set $s_k = \alpha_k x_k$ and update $\beta_{k+1} = \beta_k + s_k$.
	\item Set $y_k = \nabla_{\beta}(\beta_k) - \nabla_{\beta}(\beta_{k+1})$.
	\item Update 
	$$
	  B_{k+1} = B_k + \frac{y_ky_k^T}{y_k^Ts_k} - \frac{B_ks_ks_k^TB_k^T}{s_k^TB_k s_k}.
	$$
\end{enumerate}
The BFGS algorithm is a possible optimization method in R's \text{optim} function. There is also a variant of BFGS in R called L-BFGS-B. This algorithm extends a limited memory variant of BFGS to handle bound constraints in the domain space of $l(\beta)$.  Bound constraints are of the form $l_i \leq \beta_i \leq u_i$ where $\beta_i$ is one component of the canonical parameter vector $\beta$. 



\vspace*{0.5cm}\noindent{\bf Stochastic Gradient Decent (SGD)}: The SGD algorithm with averaging \citep{polyak1992acceleration} is a computationally fast, and scalable optimization method that is applicable in large scale applications with applications in online learning. We will consider SGD in our context for estimating $\hat\beta$ in exponential family models. The SGD algorithm only requires use of one (or relatively few) data points at each iteration, which makes it computationally superior to other optimization routines. Conventional implementations average over all iterations to derive the final estimator. Consistency and asymptotic normality properties of SGD have been verified in \cite{polyak1992acceleration} for both parameter estimation. In addition to these results, \cite{rakhlin2011making} derived the optimal rates of $O(1/n)$ for the objective function under smoothness and strong convexity assumptions. These assumptions hold in our modeling context.

We will suppose that we have data $D_n = Z_1,\ldots,Z_n$ drawn as iid copies of $Z = (y,x)$. In this case we assume that the both the response and the predictors are random from some common generative process. We will suppose that the conditional distibution of interest $y|x$ can then be parameterized as an exponential family with log likelihood \eqref{subloglike} where the matrix $M$ has rows $x_i^T$, $i = 1,\ldots,n$. The SGD algorithm updates as follows: 
$$
  \hat{\beta}_{k} = \hat\beta_{k-1} + \eta_{k}\nabla l(\hat\beta_{k-1}; Z_{k})
$$
for $k = 1,\ldots,n$ where $\eta$ is called the learning rate. We set the learning rate to be $\eta_k = Ck^{-\alpha}$ for some $\alpha \in (0, 1)$. The final SGD estimators is then
$$
  \hat\beta = \frac{1}{n}\sum_{k=1}^n \hat{\beta}_{k}.
$$


\noindent We will revisit optimization when we discuss specific GLMs.







\section*{Sufficiency}

A (possibly vector-valued) statistic is \emph{sufficient} if the conditional distribution of the full data given this statistic does not depend on the parameter. 


The interpretation is that the full data provides no information about the parameter that is not already provided by the sufficient statistic. The principle of sufficiency follows: all inference should depend on the data only through sufficient statistics.

The Fisher-Neyman factorization criterion \citep[Corollary 1 of Chapter 2]{lehmann1959testing} says that a statistic is sufficient if and only if the likelihood depends on the whole data only through that statistic. %It follows that Bayesian inference always obeys the likelihood principle. It also follows that likelihood inference can obey the likelihood principle, although this is not automatic. The maximum likelihood estimator (MLE), the likelihood ratio test statistic, and observed and expected Fisher information with the MLE plugged in all depend on the data only through the likelihood, hence obey the sufficiency principle. Other procedures that are sometimes considered part of likelihood inference, like one-step Newton updates of root-$n$-consistent estimators, do not necessarily obey the sufficiency principle.

\begin{lem}
The canonical statistic vector of an exponential family is a sufficient statistic.
\end{lem}

%\vspace{0.5cm}
\noindent{\bf The proof of the above Lemma is left as an exercise for the reader.}

\vspace{0.5cm} Sufficient dimension reduction is a whole field of study. However, the \emph{original} ``sufficient dimension reduction'' theory was about exponential families. The so-called Pitman-Koopman-Darmois theorem (proved independently by three different persons in 1935 and 1936) says that 
\begin{quote}
when we have IID sampling from a statistical model, all distributions in the model have the same support which does not depend on the parameter, and all distributions in the model are continuous, then there is a sufficient statistic whose dimension does not depend on the parameter if and only if the statistical model is an exponential family of distributions.	
\end{quote}
This theorem was responsible for the interest in exponential families early in the twentieth century. The condition of the Pitman-Koopman-Darmois theorem that the support does not depend on the parameter is essential. For IID sampling from the Uniform$(0,\theta)$ model the maximal order statistic $X_{(n)}$ is sufficient. Its dimension (one) does not depend on $n$. To show this note that the likelihood is
\begin{align*}
  L_n(\theta) &= \prod_{i=1}^n \frac{1}{\theta} I_{(0,\theta)}(X_i) \\
    &= \frac{1}{\theta^n} \prod_{i=1}^n I_{(0,\theta)}(X_i) \\
    &= \frac{1}{\theta^n} I_{(0,\theta)}(X_{(n)})
\end{align*}
because if $X_{(n)} < \theta$ then $X_i < \theta$ for all $i$,

The condition that the statistical model has to be continuous is ugly. Many of the most important applications of exponential family theory (logistic and Poisson regression, log-linear models for categorical data) are discrete, and the theorem does not say anything about them. But later theorems that did cover discrete distributions need extra conditions that seem just there so the theorem can be proved. %(my brother-in-law’s thesis advisor called these “ham and eggs theorems” — if we had some ham, we’d have ham and eggs, if we had some eggs).

Interest in exponential families changed direction in the 1970’s with the invention of generalized linear models \citep{nelder1972generalized, wedderburn1974quasi} and log-linear models for categorical data \citep{bishop2007discrete} and with the publication of authoritative treatises \citep{barndorff2014information, brown1986fundamentals} which used the mathematics of convex analysis \citep{rockafellar1970convex}.

In that context the sufficient dimension reduction for canonical linear submodels (exponential family regression models) became more important than the Pitman-Koopman-Darmois property. This is the relation between the canonical sufficient statistic $y$ of the saturated model and the canonical sufficient statistic $M^Ty$ of a canonical linear submodel. The former has the row dimension of $M$ and the latter has the column dimension of $M$, which is usually much smaller.



\section*{Maximum Entropy}

Entropy is a physical quantity involved in the second law of thermodynamics, which says that the the total entropy of an isolated physical system is nondecreasing in any physical process. It has to do with the maximum possible efficiency of a heat engine or refrigerator, with which chemical reactions proceed spontaneously, and with many other things.

Ludwig Boltzmann and Josiah Willard Gibbs figured out the connection between entropy and probability and between the thermodynamic properties of bulk matter and the motions and interactions of atoms and molecules.

In this theory entropy is not certain to increase to its maximum possible value. It is only overwhelmingly probable to do so in any large system. In a very small system, such as a cubic micrometer of air, it is less probable that entropy will be near its maximum value. In such a small system the statistical fluctuations are large. This is the physical manifestation of the law of large numbers. The larger the sample size (the more molecules involved) the less stochastic variation. Boltzmann thought this discovery so important that he had $S = k\log W$ inscribed on his tombstone ($S$ is entropy, $W$ is probability, and $k$ is a constant of nature now known as Boltzmann’s constant).

Claude Shannon imported entropy into information theory, using it to determine the maximum throughput of a noisy communication channel. Shannon information is negative entropy (minus log probability). Kullback and Leibler imported the same concept into statistics, where it is usually called \emph{Kullback-Leibler information}. It is expected log likelihood and hence what likelihood attempts to estimate.

Edwin Jaynes, a physicist, introduced the ``maximum entropy formalism" that describes exponential families in terms of entropy. To keep the derivation simple, we will do the finite sample space case. The same idea can be extended to the infinite discrete case or the continuous case, although the math is harder.

The \emph{relative entropy} of a distribution with PMF $f$ to a distribution with PMF $m$ is defined to be 
$$
  -\sum_{x\in S} f(x)\log\left(\frac{f(x)}{m(x)}\right),
$$
where $S$ is the support of the distribution with PMF $m$. (It is the negative of this quantity that is Kullback-Leibler information of $f$ with respect to $m$.) It is actually not necessary that $m$ be a PMF; any positive function will do.


Suppose we ``know" the value of some expectations
$$
  \mu_j = \E\left(t_j(X)\right) = \sum_{x\in S} t_j(x)f(x), \qquad j \in J,
$$
and we want $f$ to maximize entropy subject to these constraints plus the constraints that $f$ is nonnegative and sums to one. That is, we want to solve the following optimization problem
\begin{align*}
	\text{maximize} \;& -\sum_{x \in S} f(x)\log\left(\frac{f(x)}{m(x)}\right) \\
	\text{subject to} \;& \sum_{x\in S} t_j(x)f(x) = \mu_j, \qquad j \in J \\
	&\sum_{x \in S} f(x) = 1 \\
	&f(x) \geq 0, \qquad x \in S
\end{align*}
It turns out that the inequality constraints here are unnecessary. If we solve the problem without requiring $f$ be nonnegative, the solution happens to be nonnegative. But we do need to enforce the equality constraints.

To do that, we use the method of Lagrange multipliers. Multiply each constraint function by a new parameter (Lagrange multiplier) and add to the objective function. This gives the Lagrangian function
\begin{align*}
	\mathcal{L}(f) &= -\sum_{x \in S} f(x)\log\left(\frac{f(x)}{m(x)}\right) 
	  + \sum_{j\in J}\theta_j \sum_{x\in S} t_j(x)f(x) + \psi\sum_{x \in S} f(x) \\
	  &= -\sum_{x \in S} f(x)\left[\log\left(\frac{f(x)}{m(x)}\right) - \sum_{j\in J}\theta_j t_j(x) - \psi\right],
\end{align*}
where $\theta_j$ and $\psi$ are the Lagrange multipliers.

Because the domain of $f$ is finite, we can think of it as a vector having components $f(x)$. The Lagrangian is maximized where its first derivative is zero, so we calculate the first partial derivatives as
$$
\frac{\partial \mathcal{L}(f)}{\partial f(x)} = -\log\left(\frac{f(x)}{m(x)}\right) + \sum_{j\in J}\theta_j t_j(x) + \psi - 1,
$$
setting this equal to zero and solving for $f(x)$ gives 
$$
  f(x) = m(x)\exp\left(\sum_{j\in J}\theta_jt_j(x) + \psi - 1\right).
$$
We then have to find the value of the Lagrange multipliers that make all of the constraints satisfied. In aid of this, define $\theta$ to be the vector having components $\theta_j$ and $t(x)$ to be the vector having components $t_j(x)$, so that we can write
$$
  f(x) = m(x)\exp\left(t(x)^T\theta + \psi - 1\right).
$$
In order to satisfy the constraint that the probabilities sum to one we must
have
$$
  e^{\psi - 1}\sum_{x\in S}m(x)e^{t(x)^T\theta} = 1
$$
or
$$
  1 - \psi = \log\left(\sum_{x\in S}m(x)e^{t(x)^T\theta}\right).
$$
Now define
$$
  c(\theta) = \log\left(\sum_{x\in S}m(x)e^{t(x)^T\theta}\right).
$$
Then,
$$
  f(x) = m(x)e^{t(x)^T\theta - c(\theta)},
$$
and this is the density of an exponential family! If we think of the Lagrange multipliers $\theta_j$ as unknown parameters rather than constants we still have to adjust, then we see that we have an exponential family with canonical statistic vector $t(x)$, canonical parameter vector $\theta$, and cumulant function $c(\theta)$.

Define $\mu$ to be the vector with components $\mu_j$. Then we know from exponential family that
$$
  \mu = \nabla c(\theta) = g(\theta)
$$
and $g$ is a one-to-one function (if the exponential family is identifiable, which happens if there are no redundant constraints), so the Lagrange multiplier vector is 
$$
  \theta = g^{-1}(\mu)
$$
and, although we do not have a closed form expression for $g^{-1}$, we can evaluate $g^{-1}(\mu)$ for any $\mu$ that is a possible mean-value parameter vector found by optimization. Our use of the maximum entropy argument is a bit peculiar. First we said that we ``knew" the expectations
$$
  \mu = \E\{t(X)\},
$$
and wanted to pick out one probability distribution that maximizes entropy and satisfies this constraint. Then we forgot about ``knowing" this constraint and said as $\mu$ ranges over all possible values we get an exponential family of probability distributions. Also we have to choose a base measure.

Despite this rather odd logic, the maximum entropy argument does say something important about exponential families. Suppose we have a big exponential family (a ``saturated model") and are interested in submodels. Examples are Bernoulli regression, Poisson regression, or categorical data analysis. The maximum entropy argument says the canonical linear submodels are the submodels that, \emph{subject to constraining the means of their submodel canonical statistics, leave all other aspects of the data as random as possible}, where ``as random as possible" means maximum entropy. Thus these models constrain the means of their canonical statistics and anti-constrain (leave as unconstrained as possible) everything else.

In choosing a particular canonical linear submodel parameterization $\theta = M\beta$ we are, in effect, modeling only the the distribution of the submodel canonical statistic $t(y) = M^T y$, leaving all other aspects of the distribution of $y$ as random as possible given the control over the distribution of $t(y)$.


\section*{Overdispersion (before we summarize)}

A common explanation for large deviance (or poor fit) is the presence of a few outliers. When large number of points are identified as outliers, they become unexceptional, and it may be the case that the error distribution is misspecified. In the presence of misspecification in the form of overdispersion, the exponential family takes on a different functional form
\begin{equation} \label{expofamdisp}
  f(y|\theta,\phi) = \exp\left(\frac{\inner{y,\theta}- c(\theta)}{a(\phi)} - b(y,\phi) \right),
\end{equation}
where $y$ and $\theta$ are as before, $\phi$ is a dispersion parameter, and $b(y,\phi)$ is a function of the data $y$ and the dispersion parameter $\phi$. From the perspective of the canonical exponential families that we have motivated throughout, the function $b(y,\phi)$ is similar to the base measure $h$ that was dropped from consideration in log likelihood based arguments that focused on the parameters. Notice that the density \eqref{expofamdisp} is a generalization of the exponential family density which specifies that $a(\phi) = 1$ and $b(y,\phi) = \log(h(y))$. Note that the dispersion parameter can be estimated using
$$
  \hat{\phi} = \frac{\sum_{i=1}^n(y - \hat\mu_i)^2/\hat\mu_i}{n-p}.
$$
We investigate overdispersion when we cover GLMs for count responses.


\section*{Interpretation}

So now we can put all of this together to discuss interpretation of regular full exponential families and their canonical linear submodels.

The MLE is unique if it exists (from strict concavity). Existence is a complicated story, and non-existence results in complicated problems of interpretation, which we leave for now. We will revisit non-existence later.

The MLE satisfies the observed equals expected property, either \eqref{obsequalsexp} for a saturated model or \eqref{submodelmvp} for a canonical linear submodel.

The sufficient dimension reduction property and maximum entropy property say that $M^Ty$ is a sufficient statistic, hence captures all information about the parameter. All other aspects of the distribution of $y$ are left as random as possible; the canonical linear submodel does not constrain them in any way other than its constraints on the expectation of $M^Ty$.

A quote from Charlie Geyer:
\begin{quote}
``Parameters are meaningless quantities. Only probabilities and expectations are meaningful."	
\end{quote}
Of course, some parameters are probabilities and expectations, but most exponential family canonical parameters are not. Also note that the same model can be specified by different formulas or different model matrices, so that a particular canonical parameter value does not specify a model uniquely. A quote from Alice in Wonderland (taken from Charlie Geyer):
\begin{quote}
`If there’s no meaning in it,' said the King, `that saves a world
of trouble, you know, as we needn’t try to find any.'		
\end{quote}
Realizing that canonical parameters are meaningless quantities ``saves a world of trouble.'' We ``needn’t try to find any.''

Hence our interpretations should be focused on mean value parameters. This conclusion flies in the face the traditional way regression models are taught. In most courses, students are taught to ``interpret" the equation $\theta = M\beta$, or, more precisely, since in lower level courses students aren’t assumed to know about matrices, students are taught to interpret this with the matrix multiplication written out explicitly, interpreting equations like
$$
  \theta_i = \beta_0 + \beta_1x_i + \beta_2 x_i^2, \qquad \text{where} \; i \; \text{runs over cases}.
$$
The model matrix $M$ determines two linear transformations
\begin{align*}
  \beta &\mapsto M\beta	\\
  \mu &\mapsto M^T\mu
\end{align*}
We claim, that the second one, which takes saturated model canonical statistic to submodel canonical statistic and saturated model mean value parameter to submodel mean value parameter, is the more important of the two and should lead in interpretation, because the former is about canonical parameters (the meaningless ones) and the latter is about mean value parameters (the meaningful ones). This is especially so in light of the fact that $M^Ty = M^T\hat\mu$ (observed equals expected) is the only algebraically simple property of maximum likelihood that users can hang an interpretation on. So we need to rethink the way we teach regression and interpret regression when talking to users.

When we do need to think about canonical parameters, the key concept is the multivariate monotone relationship \eqref{multiparm} between canonical and mean value parameters. Note that this holds not only for saturated model parameters but also for canonical linear submodel parameters. If, as before, we let $\tau = M^T\mu$ denote the submodel mean value parameter, and $\tau_1$ corresponds to $\beta_1$ and $\tau_2$ to $\beta_2$, then
$$
  (\tau_1 - \tau_2)^T(\beta_1 - \beta_2) > 0, \qquad \text{whenever} \; \tau_1 \neq \tau_2.
$$

By standard theory of maximum likelihood, MLEs of all parameters are consistent, efficient (have minimum asymptotic variance), and asymptotically normal, with easily calculated asymptotic variance (inverse Fisher information matrix). Fisher information is easily calculated, \eqref{FI} is Fisher information for the saturated model canonical parameter $\theta$;
$$
  \nabla^2_\beta c(M\beta) = M^T\left[\nabla c(M\beta)\right]M
$$
is Fisher information for the submodel canonical parameter $\beta$.

The Delta method then gives asymptotic variance matrices for mean value parameters. If $\mu = g(\theta)$, then the asymptotic variance for $\hat\mu$ is
$$
  [\nabla g(\theta)]I(\theta)^{-1}[\nabla g(\theta)]^T = I(\theta)I(\theta)^{-1}I(\theta) = I(\theta)
$$
and $M^TI(\theta)M$ is the asymptotic variance for $\hat\tau$. These can be used for hypothesis tests and confidence intervals about these other parameters.



\section*{Acknowledgments}
These notes take materials from Charles Geyer's notes on exponential families and other topics. We also borrow materials from Trevor Park's STAT 426 notes and \cite{agresti2013cat}.



\bibliographystyle{plainnat}
\bibliography{../note_sources}


\end{document}






